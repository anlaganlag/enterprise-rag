"""
ä¿é™©äº§å“RAGç³»ç»Ÿ - è‡ªå®šä¹‰å¯¼èˆªç‰ˆæœ¬
è§£å†³æ ‡ç­¾é¡µè·³è½¬é—®é¢˜
"""
import streamlit as st
import os
from typing import List, Dict
import json
from datetime import datetime
import pandas as pd
import time

# æ ¸å¿ƒåº“
import openai
from langchain.text_splitter import RecursiveCharacterTextSplitter
from langchain_openai import OpenAIEmbeddings, ChatOpenAI
from langchain_community.vectorstores import FAISS
from langchain.chains import RetrievalQA
import PyPDF2
import pdfplumber

# é¡µé¢é…ç½®
st.set_page_config(
    page_title="ä¿é™©äº§å“æ™ºèƒ½é—®ç­”ç³»ç»Ÿ",
    page_icon="ğŸ¥",
    layout="wide",
    initial_sidebar_state="expanded"
)

# è‡ªå®šä¹‰CSSæ ·å¼
st.markdown("""
<style>
    .nav-button {
        display: inline-block;
        padding: 0.5rem 1rem;
        margin: 0.2rem;
        background: #f0f2f6;
        border-radius: 8px;
        text-align: center;
        cursor: pointer;
        transition: all 0.3s;
    }
    
    .nav-button:hover {
        background: #667eea;
        color: white;
    }
    
    .nav-button.active {
        background: #667eea;
        color: white;
        font-weight: bold;
    }
    
    .question-card {
        background: #f8f9fa;
        border-left: 4px solid #667eea;
        padding: 0.8rem;
        margin: 0.5rem 0;
        border-radius: 5px;
    }
    
    .confidence-high {
        background: #28a745;
        color: white;
        padding: 4px 12px;
        border-radius: 20px;
        font-size: 12px;
    }
    
    .confidence-medium {
        background: #ffc107;
        color: white;
        padding: 4px 12px;
        border-radius: 20px;
        font-size: 12px;
    }
    
    .confidence-low {
        background: #dc3545;
        color: white;
        padding: 4px 12px;
        border-radius: 20px;
        font-size: 12px;
    }
    
    .answer-card {
        background: #f0f9ff;
        border-radius: 10px;
        padding: 1.5rem;
        margin: 1rem 0;
    }
    
    .category-header {
        background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
        color: white;
        padding: 0.8rem 1.2rem;
        border-radius: 10px;
        margin-bottom: 0.5rem;
        font-weight: bold;
    }
</style>
""", unsafe_allow_html=True)

# åˆå§‹åŒ–session state
if 'current_page' not in st.session_state:
    st.session_state.current_page = "æ™ºèƒ½é—®ç­”"
if 'vector_store' not in st.session_state:
    st.session_state.vector_store = None
if 'qa_history' not in st.session_state:
    st.session_state.qa_history = []
if 'documents' not in st.session_state:
    st.session_state.documents = []
if 'selected_question' not in st.session_state:
    st.session_state.selected_question = ""
if 'auto_submit' not in st.session_state:
    st.session_state.auto_submit = False
if 'last_answer' not in st.session_state:
    st.session_state.last_answer = None

# é—®é¢˜åˆ†ç±»ç»“æ„
QUESTION_CATEGORIES = {
    "ğŸ“¦ äº§å“ä¿¡æ¯": {
        "questions": [
            ("ä¿é™©å…¬å¸åç§°", "What is the insurer entity name?", True),
            ("äº§å“åç§°", "What is the product name?", True),
            ("äº§å“èµ„äº§é…ç½®", "What is the product asset mix?", True),
            ("äº§å“ç±»å‹", "What is the product type?", True),
            ("å‘è¡Œåœ°åŒº", "What is the issuing jurisdiction?", True),
        ],
        "completion": "9/9"
    },
    "ğŸ“„ è®¡åˆ’è¯¦æƒ…": {
        "questions": [
            ("æœ€ä½ä¿è´¹", "What is the minimum premium?", True),
            ("æŠ•ä¿å¹´é¾„", "What is the issue age range?", True),
            ("ä¿å•è´§å¸", "What are the policy currencies?", True),
            ("ç¼´è´¹æœŸé™", "What are the premium terms?", True),
            ("èº«æ•…èµ”ä»˜ç‰¹ç‚¹", "What are the death settlement features?", True),
        ],
        "completion": "9/11"
    },
    "ğŸ’° åˆ†çº¢å‹ç»ˆèº«å¯¿é™©": {
        "questions": [
            ("é¦–æ—¥ä¿è¯ç°é‡‘ä»·å€¼", "What is the Day 1 GCV?", True),
            ("é€€ä¿ä»·å€¼ç»„æˆ", "What are the surrender value components?", True),
            ("èº«æ•…èµ”ä»˜ç»„æˆ", "What are the death benefit components?", True),
        ],
        "completion": "3/3"
    }
}

# çƒ­é—¨å¿«é€Ÿé—®é¢˜
HOT_QUESTIONS = [
    ("æœ€ä½ä¿è´¹", "RoyalFortuneçš„æœ€ä½ä¿è´¹æ˜¯å¤šå°‘ï¼Ÿ"),
    ("æŠ•ä¿å¹´é¾„", "æŠ•ä¿å¹´é¾„èŒƒå›´æ˜¯ä»€ä¹ˆï¼Ÿ"),
    ("ä¿è¯ç°é‡‘ä»·å€¼", "ä¿è¯ç°é‡‘ä»·å€¼æ˜¯å¤šå°‘ï¼Ÿ"),
    ("èº«æ•…èµ”ä»˜", "èº«æ•…èµ”ä»˜æœ‰å“ªäº›ç‰¹ç‚¹ï¼Ÿ"),
]

def initialize_openai():
    """åˆå§‹åŒ–OpenAIå®¢æˆ·ç«¯"""
    api_key = None
    
    # ä».envæ–‡ä»¶è¯»å–
    try:
        from dotenv import load_dotenv
        load_dotenv()
        api_key = os.getenv("OPENAI_API_KEY")
    except:
        pass
    
    if api_key:
        openai.api_key = api_key
        os.environ["OPENAI_API_KEY"] = api_key
    
    return api_key

@st.cache_data
def process_pdf(uploaded_file) -> List[Dict]:
    """å¤„ç†PDFæ–‡ä»¶"""
    chunks = []
    try:
        with pdfplumber.open(uploaded_file) as pdf:
            text = ""
            for page_num, page in enumerate(pdf.pages, 1):
                page_text = page.extract_text() or ""
                text += f"\n[Page {page_num}]\n{page_text}\n"
                
                tables = page.extract_tables()
                for table in tables:
                    if table:
                        df = pd.DataFrame(table[1:], columns=table[0])
                        text += f"\n[Table on Page {page_num}]\n{df.to_string()}\n"
        
        text_splitter = RecursiveCharacterTextSplitter(
            chunk_size=800,
            chunk_overlap=200
        )
        
        chunks = text_splitter.split_text(text)
        return [{"content": chunk, "metadata": {"source": uploaded_file.name}} for chunk in chunks]
    
    except Exception as e:
        st.error(f"PDFå¤„ç†é”™è¯¯: {str(e)}")
        return []

def create_vector_store(documents: List[Dict]):
    """åˆ›å»ºå‘é‡å­˜å‚¨"""
    try:
        embeddings = OpenAIEmbeddings()
        texts = [doc["content"] for doc in documents]
        metadatas = [doc["metadata"] for doc in documents]
        
        vector_store = FAISS.from_texts(
            texts=texts,
            embedding=embeddings,
            metadatas=metadatas
        )
        return vector_store
    except Exception as e:
        st.error(f"åˆ›å»ºå‘é‡å­˜å‚¨å¤±è´¥: {str(e)}")
        return None

def answer_question_with_confidence(question: str, vector_store) -> Dict:
    """å›ç­”é—®é¢˜å¹¶è¿”å›ç½®ä¿¡åº¦"""
    try:
        if not os.getenv("OPENAI_API_KEY"):
            return {
                "question": question,
                "answer": "è¯·å…ˆè®¾ç½®OpenAI APIå¯†é’¥",
                "sources": [],
                "confidence": 0.0,
                "timestamp": datetime.now().isoformat()
            }
        
        llm = ChatOpenAI(
            model_name="gpt-3.5-turbo",
            temperature=0.1,
            max_tokens=500
        )
        
        # å¢åŠ æ£€ç´¢æ–‡æ¡£æ•°é‡åˆ°10ä¸ª
        qa_chain = RetrievalQA.from_chain_type(
            llm=llm,
            chain_type="stuff",
            retriever=vector_store.as_retriever(search_kwargs={"k": 10}),
            return_source_documents=True
        )
        
        start_time = time.time()
        result = qa_chain({"query": question})
        response_time = time.time() - start_time
        
        source_documents = result.get("source_documents", [])
        
        # æ›´ç²¾ç»†çš„ç½®ä¿¡åº¦è®¡ç®—
        confidence = 0.3  # åŸºç¡€ç½®ä¿¡åº¦
        if source_documents:
            # æ ¹æ®æ–‡æ¡£æ•°é‡è°ƒæ•´ç½®ä¿¡åº¦
            doc_count = len(source_documents)
            if doc_count >= 8:
                confidence = 0.95
            elif doc_count >= 5:
                confidence = 0.85
            elif doc_count >= 3:
                confidence = 0.75
            elif doc_count >= 1:
                confidence = 0.6
        
        # å¤„ç†æ‰€æœ‰æºæ–‡æ¡£ï¼ˆæœ€å¤š10ä¸ªï¼‰
        sources = []
        for i, doc in enumerate(source_documents[:10], 1):
            # å¢åŠ æ˜¾ç¤ºçš„æ–‡æœ¬é•¿åº¦åˆ°500å­—ç¬¦
            content = doc.page_content
            # æ¸…ç†æ–‡æœ¬ï¼Œå»é™¤å¤šä½™çš„æ¢è¡Œå’Œç©ºæ ¼
            content = ' '.join(content.split())
            
            sources.append({
                "doc_name": doc.metadata.get("source", "Unknown"),
                "content": content[:500] + ("..." if len(content) > 500 else ""),
                "full_content": content,  # ä¿å­˜å®Œæ•´å†…å®¹
                "score": 0.95 - (i * 0.05),  # æ ¹æ®æ’åºç»™å‡ºé€’å‡çš„ç›¸å…³åº¦åˆ†æ•°
                "index": i
            })
        
        return {
            "question": question,
            "answer": result["result"],
            "sources": sources,
            "confidence": confidence,
            "response_time": response_time,
            "timestamp": datetime.now().isoformat()
        }
    except Exception as e:
        return {
            "question": question,
            "answer": f"é”™è¯¯: {str(e)}",
            "sources": [],
            "confidence": 0.0,
            "response_time": 0,
            "timestamp": datetime.now().isoformat()
        }

def display_confidence_badge(confidence: float):
    """æ˜¾ç¤ºç½®ä¿¡åº¦æ ‡ç­¾"""
    percentage = confidence * 100
    if confidence >= 0.7:
        badge_class = "confidence-high"
        emoji = "âœ…"
    elif confidence >= 0.3:
        badge_class = "confidence-medium"
        emoji = "âš ï¸"
    else:
        badge_class = "confidence-low"
        emoji = "âŒ"
    
    st.markdown(
        f'<span class="{badge_class}">{emoji} ç½®ä¿¡åº¦: {percentage:.1f}%</span>',
        unsafe_allow_html=True
    )

# ä¸»ç•Œé¢
st.title("ğŸ¤– ä¿é™©äº§å“æ™ºèƒ½é—®ç­”ç³»ç»Ÿ")
st.markdown("### åŸºäºRAGæŠ€æœ¯çš„ä¼ä¸šçº§PoCæ¼”ç¤º | æ”¯æŒä¸­è‹±æ–‡æ™ºèƒ½é—®ç­”")

# ä¾§è¾¹æ 
with st.sidebar:
    st.header("âš™ï¸ ç³»ç»Ÿé…ç½®")
    
    # APIå¯†é’¥ç®¡ç†
    api_key = initialize_openai()
    
    # åˆ›å»ºä¸€ä¸ªå¯æŠ˜å çš„APIé…ç½®åŒºåŸŸ
    with st.expander("ğŸ”‘ APIå¯†é’¥é…ç½®", expanded=not bool(api_key)):
        if api_key:
            # æ˜¾ç¤ºå½“å‰APIå¯†é’¥çŠ¶æ€
            st.success("âœ… APIå¯†é’¥å·²é…ç½®")
            # æ˜¾ç¤ºéƒ¨åˆ†éšè—çš„å¯†é’¥
            masked_key = api_key[:10] + "..." + api_key[-4:] if len(api_key) > 14 else "***"
            st.info(f"å½“å‰å¯†é’¥: {masked_key}")
            
            # æä¾›é‡æ–°é…ç½®é€‰é¡¹
            if st.button("ğŸ”„ é‡æ–°é…ç½®APIå¯†é’¥", use_container_width=True):
                # æ¸…é™¤ç°æœ‰å¯†é’¥
                if 'api_key' in st.session_state:
                    del st.session_state.api_key
                os.environ.pop("OPENAI_API_KEY", None)
                st.rerun()
        
        # APIå¯†é’¥è¾“å…¥æ¡†
        new_api_key = st.text_input(
            "è¾“å…¥æ–°çš„OpenAI API Key",
            type="password",
            help="æ ¼å¼: sk-...",
            placeholder="sk-proj-..."
        )
        
        col1, col2 = st.columns(2)
        with col1:
            if st.button("âœ… ä¿å­˜å¯†é’¥", use_container_width=True, type="primary"):
                if new_api_key and new_api_key.startswith("sk-"):
                    os.environ["OPENAI_API_KEY"] = new_api_key
                    st.session_state.api_key = new_api_key
                    st.success("âœ… APIå¯†é’¥å·²æ›´æ–°")
                    time.sleep(1)
                    st.rerun()
                elif new_api_key:
                    st.error("âŒ å¯†é’¥æ ¼å¼ä¸æ­£ç¡®ï¼Œåº”ä»¥'sk-'å¼€å¤´")
        
        with col2:
            # ä».envæ–‡ä»¶é‡æ–°åŠ è½½
            if st.button("ğŸ“‚ ä».envåŠ è½½", use_container_width=True):
                try:
                    from dotenv import load_dotenv
                    load_dotenv(override=True)
                    env_key = os.getenv("OPENAI_API_KEY")
                    if env_key:
                        os.environ["OPENAI_API_KEY"] = env_key
                        st.session_state.api_key = env_key
                        st.success("âœ… å·²ä».envæ–‡ä»¶åŠ è½½å¯†é’¥")
                        time.sleep(1)
                        st.rerun()
                    else:
                        st.error("âŒ .envæ–‡ä»¶ä¸­æœªæ‰¾åˆ°OPENAI_API_KEY")
                except Exception as e:
                    st.error(f"âŒ åŠ è½½å¤±è´¥: {str(e)}")
        
        # æµ‹è¯•APIè¿æ¥
        if api_key or new_api_key:
            if st.button("ğŸ§ª æµ‹è¯•APIè¿æ¥", use_container_width=True):
                test_key = new_api_key if new_api_key else api_key
                with st.spinner("æ­£åœ¨æµ‹è¯•è¿æ¥..."):
                    try:
                        # æµ‹è¯•APIè¿æ¥
                        from openai import OpenAI
                        client = OpenAI(api_key=test_key)
                        # å‘é€ä¸€ä¸ªç®€å•çš„æµ‹è¯•è¯·æ±‚
                        response = client.chat.completions.create(
                            model="gpt-3.5-turbo",
                            messages=[{"role": "user", "content": "Hi"}],
                            max_tokens=5
                        )
                        st.success("âœ… APIè¿æ¥æˆåŠŸï¼")
                        st.info(f"æ¨¡å‹å“åº”: {response.choices[0].message.content}")
                    except Exception as e:
                        st.error(f"âŒ APIè¿æ¥å¤±è´¥: {str(e)}")
                        if "api_key" in str(e).lower():
                            st.warning("ğŸ’¡ æç¤º: è¯·æ£€æŸ¥APIå¯†é’¥æ˜¯å¦æ­£ç¡®")
                        elif "rate" in str(e).lower():
                            st.warning("ğŸ’¡ æç¤º: APIè°ƒç”¨é¢‘ç‡é™åˆ¶ï¼Œè¯·ç¨åå†è¯•")
                        else:
                            st.warning("ğŸ’¡ æç¤º: è¯·æ£€æŸ¥ç½‘ç»œè¿æ¥æˆ–APIå¯†é’¥æƒé™")
    
    st.divider()
    
    # æ–‡ä»¶ä¸Šä¼ 
    st.header("ğŸ“„ æ–‡æ¡£ç®¡ç†")
    uploaded_files = st.file_uploader(
        "é€‰æ‹©PDFæ–‡ä»¶",
        type=["pdf"],
        accept_multiple_files=True
    )
    
    if uploaded_files:
        st.info(f"å·²é€‰æ‹© {len(uploaded_files)} ä¸ªæ–‡ä»¶")
        
        if st.button("ğŸ”„ å¤„ç†æ–‡æ¡£", use_container_width=True, type="primary"):
            if not api_key:
                st.error("âŒ è¯·å…ˆè®¾ç½®OpenAI APIå¯†é’¥")
            else:
                with st.spinner("æ­£åœ¨å¤„ç†PDFæ–‡æ¡£..."):
                    all_documents = []
                    for file in uploaded_files:
                        docs = process_pdf(file)
                        all_documents.extend(docs)
                    
                    if all_documents:
                        st.session_state.documents = all_documents
                        st.session_state.vector_store = create_vector_store(all_documents)
                        st.success(f"âœ… æˆåŠŸå¤„ç†ï¼Œå…± {len(all_documents)} ä¸ªæ–‡æœ¬å—")
                        st.balloons()

# ä¸»è¦å†…å®¹åŒºåŸŸ
if st.session_state.vector_store:
    # æ˜¾ç¤ºç³»ç»ŸçŠ¶æ€
    status_cols = st.columns(4)
    with status_cols[0]:
        st.metric("æ–‡æ¡£æ•°", len(set([d["metadata"]["source"] for d in st.session_state.documents])))
    with status_cols[1]:
        st.metric("æ–‡æœ¬å—", len(st.session_state.documents))
    with status_cols[2]:
        st.metric("å†å²é—®ç­”", len(st.session_state.qa_history))
    with status_cols[3]:
        st.metric("ç³»ç»ŸçŠ¶æ€", "âœ… å°±ç»ª")
    
    # è‡ªå®šä¹‰å¯¼èˆªæ 
    st.markdown("---")
    nav_cols = st.columns(4)
    
    pages = ["ğŸ’¬ æ™ºèƒ½é—®ç­”", "ğŸ“‹ é—®é¢˜åˆ†ç±»", "ğŸ“Š æ‰¹é‡é—®ç­”", "ğŸ“œ å†å²è®°å½•"]
    
    for i, page in enumerate(pages):
        with nav_cols[i]:
            if st.button(page, key=f"nav_{i}", use_container_width=True,
                        type="primary" if st.session_state.current_page == page.split()[1] else "secondary"):
                st.session_state.current_page = page.split()[1]
                st.rerun()
    
    st.markdown("---")
    
    # æ ¹æ®å½“å‰é¡µé¢æ˜¾ç¤ºå†…å®¹
    if st.session_state.current_page == "æ™ºèƒ½é—®ç­”":
        # å¦‚æœæœ‰å¾…å¤„ç†çš„é—®é¢˜
        if st.session_state.auto_submit and st.session_state.selected_question:
            st.info(f"ğŸ’¡ æ­£åœ¨å›ç­”é—®é¢˜ï¼š{st.session_state.selected_question}")
            
            with st.spinner("ğŸ¤” æ­£åœ¨åˆ†æ..."):
                result = answer_question_with_confidence(
                    st.session_state.selected_question, 
                    st.session_state.vector_store
                )
                st.session_state.qa_history.insert(0, result)
                st.session_state.last_answer = result
                st.session_state.auto_submit = False
            
            # æ˜¾ç¤ºç­”æ¡ˆ
            col1, col2 = st.columns([3, 1])
            with col1:
                st.markdown("### ğŸ“ AIå›ç­”")
            with col2:
                display_confidence_badge(result["confidence"])
            
            st.markdown(f"""
            <div class="answer-card">
                {result["answer"]}
            </div>
            """, unsafe_allow_html=True)
            
            # æ˜¾ç¤ºæ‰€æœ‰ä¿¡æ¯æ¥æºï¼ˆæœ€å¤š10ä¸ªï¼‰
            if result["sources"]:
                st.markdown("### ğŸ“š ä¿¡æ¯æ¥æº")
                st.info(f"æ‰¾åˆ° {len(result['sources'])} ä¸ªç›¸å…³æ–‡æ¡£ç‰‡æ®µ")
                
                for source in result["sources"]:
                    score = source.get('score', 0)
                    if score >= 0.8:
                        score_color = "ğŸŸ¢"
                    elif score >= 0.6:
                        score_color = "ğŸŸ¡"
                    else:
                        score_color = "ğŸ”´"
                    
                    with st.expander(
                        f"{score_color} æ¥æº {source.get('index', '')} | {source['doc_name']} | ç›¸å…³åº¦: {score:.2%}",
                        expanded=(source.get('index', 0) <= 3)
                    ):
                        st.markdown("**æ–‡æ¡£å†…å®¹ç‰‡æ®µï¼š**")
                        st.text_area(
                            "",
                            value=source.get('full_content', source['content']),
                            height=150,
                            disabled=True,
                            key=f"auto_source_{source.get('index', '')}_{id(source)}"
                        )
                        
                        col1, col2 = st.columns(2)
                        with col1:
                            st.caption(f"ğŸ“„ æ–‡æ¡£: {source['doc_name']}")
                        with col2:
                            st.caption(f"ğŸ“Š ç›¸å…³åº¦å¾—åˆ†: {score:.2%}")
            
            st.divider()
        
        # çƒ­é—¨é—®é¢˜
        st.markdown("#### ğŸ”¥ çƒ­é—¨é—®é¢˜")
        cols = st.columns(len(HOT_QUESTIONS))
        for i, (label, question) in enumerate(HOT_QUESTIONS):
            with cols[i]:
                if st.button(label, key=f"hot_{i}", use_container_width=True):
                    st.session_state.selected_question = question
                    st.session_state.auto_submit = True
                    st.rerun()
        
        st.divider()
        
        # æ˜¾ç¤ºæœ€è¿‘çš„å›ç­”ï¼ˆå¦‚æœæœ‰ï¼‰
        if st.session_state.last_answer and not st.session_state.auto_submit:
            st.markdown("### ğŸ“Œ æœ€è¿‘å›ç­”")
            col1, col2 = st.columns([3, 1])
            with col1:
                st.info(f"é—®é¢˜: {st.session_state.last_answer['question']}")
            with col2:
                display_confidence_badge(st.session_state.last_answer["confidence"])
            
            st.markdown(f"""
            <div class="answer-card">
                {st.session_state.last_answer["answer"]}
            </div>
            """, unsafe_allow_html=True)
            
            st.divider()
        
        # é—®é¢˜è¾“å…¥
        col1, col2 = st.columns([4, 1])
        with col1:
            question = st.text_input(
                "è¾“å…¥æ‚¨çš„é—®é¢˜",
                value="" if st.session_state.auto_submit else st.session_state.selected_question,
                placeholder="ä¾‹å¦‚: What is the minimum premium?",
                key="question_input"
            )
        with col2:
            submit_button = st.button("ğŸ” æé—®", type="primary", use_container_width=True)
        
        # å¤„ç†æé—®
        if submit_button:
            if question and question.strip():
                st.info(f"ğŸ“ æ­£åœ¨å¤„ç†é—®é¢˜: {question}")
                
                try:
                    with st.spinner("ğŸ¤” æ­£åœ¨æ€è€ƒä¸­..."):
                        result = answer_question_with_confidence(question, st.session_state.vector_store)
                        st.session_state.qa_history.insert(0, result)
                        st.session_state.last_answer = result
                    
                    # æ˜¾ç¤ºç­”æ¡ˆ
                    st.success("âœ… å›ç­”æˆåŠŸ")
                    st.markdown("---")
                    
                    col1, col2 = st.columns([3, 1])
                    with col1:
                        st.markdown("### ğŸ“ AIå›ç­”")
                    with col2:
                        display_confidence_badge(result["confidence"])
                    
                    st.markdown(f"""
                    <div class="answer-card">
                        {result["answer"]}
                    </div>
                    """, unsafe_allow_html=True)
                    
                    # æ˜¾ç¤ºå“åº”æ—¶é—´
                    if "response_time" in result:
                        st.caption(f"â±ï¸ å“åº”æ—¶é—´: {result['response_time']:.2f}ç§’")
                    
                    # æ˜¾ç¤ºæ‰€æœ‰ä¿¡æ¯æ¥æºï¼ˆæœ€å¤š10ä¸ªï¼‰
                    if result["sources"]:
                        st.markdown("### ğŸ“š ä¿¡æ¯æ¥æº")
                        st.info(f"æ‰¾åˆ° {len(result['sources'])} ä¸ªç›¸å…³æ–‡æ¡£ç‰‡æ®µ")
                        
                        # æ˜¾ç¤ºæ¯ä¸ªæ¥æº
                        for source in result["sources"]:
                            # ä½¿ç”¨ä¸åŒçš„é¢œè‰²æ ‡è®°ç›¸å…³åº¦
                            score = source.get('score', 0)
                            if score >= 0.8:
                                score_color = "ğŸŸ¢"  # é«˜ç›¸å…³åº¦
                            elif score >= 0.6:
                                score_color = "ğŸŸ¡"  # ä¸­ç›¸å…³åº¦
                            else:
                                score_color = "ğŸ”´"  # ä½ç›¸å…³åº¦
                            
                            # åˆ›å»ºå¯å±•å¼€çš„åŒºåŸŸæ˜¾ç¤ºæ¯ä¸ªæ¥æº
                            with st.expander(
                                f"{score_color} æ¥æº {source.get('index', '')} | {source['doc_name']} | ç›¸å…³åº¦: {score:.2%}",
                                expanded=(source.get('index', 0) <= 3)  # é»˜è®¤å±•å¼€å‰3ä¸ª
                            ):
                                # æ˜¾ç¤ºå†…å®¹
                                st.markdown("**æ–‡æ¡£å†…å®¹ç‰‡æ®µï¼š**")
                                st.text_area(
                                    "",
                                    value=source.get('full_content', source['content']),
                                    height=150,
                                    disabled=True,
                                    key=f"source_content_{source.get('index', '')}_{id(source)}"
                                )
                                
                                # æ˜¾ç¤ºå…ƒä¿¡æ¯
                                col1, col2 = st.columns(2)
                                with col1:
                                    st.caption(f"ğŸ“„ æ–‡æ¡£: {source['doc_name']}")
                                with col2:
                                    st.caption(f"ğŸ“Š ç›¸å…³åº¦å¾—åˆ†: {score:.2%}")
                
                except Exception as e:
                    st.error(f"âŒ å¤„ç†é—®é¢˜æ—¶å‡ºé”™: {str(e)}")
                    st.exception(e)
            else:
                st.warning("âš ï¸ è¯·è¾“å…¥é—®é¢˜")
    
    elif st.session_state.current_page == "é—®é¢˜åˆ†ç±»":
        st.markdown("### ğŸ“‹ å¯å›ç­”é—®é¢˜åˆ—è¡¨")
        st.success("ğŸ’¡ ç‚¹å‡»é—®é¢˜å°†è‡ªåŠ¨è·³è½¬åˆ°æ™ºèƒ½é—®ç­”é¡µé¢å¹¶è·å–ç­”æ¡ˆ")
        
        for category_name, category_data in QUESTION_CATEGORIES.items():
            st.markdown(f"""
            <div class="category-header">
                {category_name} {category_data['completion']}
            </div>
            """, unsafe_allow_html=True)
            
            for cn_name, en_question, is_answerable in category_data["questions"]:
                col1, col2 = st.columns([4, 1])
                with col1:
                    if is_answerable:
                        if st.button(f"âœ… {cn_name}", key=f"cat_{en_question}", 
                                   use_container_width=True):
                            # è®¾ç½®é—®é¢˜å¹¶åˆ‡æ¢é¡µé¢
                            st.session_state.selected_question = en_question
                            st.session_state.auto_submit = True
                            st.session_state.current_page = "æ™ºèƒ½é—®ç­”"
                            st.rerun()
                    else:
                        st.button(f"âŒ {cn_name}", key=f"cat_{en_question}", 
                                use_container_width=True, disabled=True)
                with col2:
                    if is_answerable:
                        st.success("å¯å›ç­”")
                    else:
                        st.error("ä¸å¯ç”¨")
    
    elif st.session_state.current_page == "æ‰¹é‡é—®ç­”":
        st.markdown("### ğŸš€ æ‰¹é‡å›ç­”é¢„è®¾é—®é¢˜")
        
        if st.button("å¼€å§‹æ‰¹é‡é—®ç­”", type="primary", use_container_width=True):
            all_questions = []
            for category_data in QUESTION_CATEGORIES.values():
                for cn_name, en_question, is_answerable in category_data["questions"]:
                    if is_answerable:
                        all_questions.append((cn_name, en_question))
            
            progress = st.progress(0)
            for i, (cn_name, question) in enumerate(all_questions):
                with st.spinner(f"å¤„ç†: {cn_name}"):
                    result = answer_question_with_confidence(question, st.session_state.vector_store)
                    st.session_state.qa_history.insert(0, result)
                    progress.progress((i + 1) / len(all_questions))
            
            st.success(f"âœ… å®Œæˆ {len(all_questions)} ä¸ªé—®é¢˜")
    
    elif st.session_state.current_page == "å†å²è®°å½•":
        st.markdown("### ğŸ“œ é—®ç­”å†å²")
        
        if st.session_state.qa_history:
            for item in st.session_state.qa_history[:10]:
                with st.expander(f"â“ {item['question'][:50]}..."):
                    st.write(f"**ç­”æ¡ˆ:** {item['answer']}")
                    if 'confidence' in item:
                        display_confidence_badge(item['confidence'])
                    st.caption(f"æ—¶é—´: {item['timestamp']}")
        else:
            st.info("æš‚æ— å†å²è®°å½•")

else:
    st.info("ğŸ‘† è¯·å…ˆåœ¨ä¾§è¾¹æ ä¸Šä¼ PDFæ–‡æ¡£å¼€å§‹ä½¿ç”¨")
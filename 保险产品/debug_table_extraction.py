"""
è¡¨æ ¼æå–è°ƒè¯•å·¥å…· - è¯Šæ–­PDFè¡¨æ ¼æå–é—®é¢˜
"""
import pdfplumber
import PyPDF2
import re
from pathlib import Path
import json

def debug_table_extraction(pdf_path):
    """è¯¦ç»†è°ƒè¯•è¡¨æ ¼æå–"""
    print(f"\n{'='*60}")
    print(f"è°ƒè¯•æ–‡ä»¶: {Path(pdf_path).name}")
    print(f"{'='*60}")
    
    results = {
        "file": Path(pdf_path).name,
        "pages": [],
        "tables_found": 0,
        "text_tables_found": 0,
        "potential_table_text": []
    }
    
    try:
        with pdfplumber.open(pdf_path) as pdf:
            print(f"æ€»é¡µæ•°: {len(pdf.pages)}")
            
            for page_num, page in enumerate(pdf.pages):
                print(f"\n--- ç¬¬ {page_num + 1} é¡µ ---")
                page_result = {
                    "page": page_num + 1,
                    "tables": [],
                    "text_tables": []
                }
                
                # æ–¹æ³•1: é»˜è®¤è¡¨æ ¼æå–
                print("å°è¯•é»˜è®¤è¡¨æ ¼æå–...")
                tables = page.extract_tables()
                if tables:
                    print(f"  âœ“ æ‰¾åˆ° {len(tables)} ä¸ªè¡¨æ ¼")
                    for i, table in enumerate(tables):
                        if table and len(table) > 0:
                            print(f"    è¡¨æ ¼{i+1}: {len(table)}è¡Œ x {len(table[0])}åˆ—")
                            # æ‰“å°å‰3è¡Œ
                            for row_idx in range(min(3, len(table))):
                                row = table[row_idx]
                                print(f"      è¡Œ{row_idx+1}: {row[:3]}..." if len(row) > 3 else f"      è¡Œ{row_idx+1}: {row}")
                            
                            page_result["tables"].append({
                                "index": i,
                                "rows": len(table),
                                "cols": len(table[0]) if table else 0,
                                "sample": table[:3] if len(table) > 3 else table
                            })
                            results["tables_found"] += 1
                else:
                    print("  âœ— æœªæ‰¾åˆ°è¡¨æ ¼")
                
                # æ–¹æ³•2: è°ƒæ•´è®¾ç½®çš„è¡¨æ ¼æå–
                print("å°è¯•è°ƒæ•´è®¾ç½®çš„è¡¨æ ¼æå–...")
                table_settings = {
                    "vertical_strategy": "text",
                    "horizontal_strategy": "text",
                    "snap_tolerance": 5,
                    "join_tolerance": 5,
                    "edge_min_length": 10,
                    "min_words_vertical": 1,
                    "min_words_horizontal": 1
                }
                
                tables_custom = page.extract_tables(table_settings=table_settings)
                if tables_custom and not tables:
                    print(f"  âœ“ è‡ªå®šä¹‰è®¾ç½®æ‰¾åˆ° {len(tables_custom)} ä¸ªè¡¨æ ¼")
                    for table in tables_custom[:1]:  # åªçœ‹ç¬¬ä¸€ä¸ª
                        if table and len(table) > 0:
                            print(f"    ç¤ºä¾‹: {table[0]}")
                
                # æ–¹æ³•3: æ£€æµ‹ä¼ªè¡¨æ ¼ï¼ˆæ–‡æœ¬å¯¹é½çš„è¡¨æ ¼ï¼‰
                print("æ£€æµ‹æ–‡æœ¬è¡¨æ ¼æ¨¡å¼...")
                text = page.extract_text()
                if text:
                    # æŸ¥æ‰¾å¯èƒ½çš„è¡¨æ ¼æ¨¡å¼
                    text_tables = detect_text_tables(text)
                    if text_tables:
                        print(f"  âœ“ æ£€æµ‹åˆ° {len(text_tables)} ä¸ªæ½œåœ¨æ–‡æœ¬è¡¨æ ¼")
                        for tt in text_tables[:2]:
                            print(f"    æ¨¡å¼: {tt['pattern']}")
                            print(f"    ç¤ºä¾‹: {tt['sample'][:100]}...")
                        
                        page_result["text_tables"] = text_tables
                        results["text_tables_found"] += len(text_tables)
                    
                    # æŸ¥æ‰¾å…³é”®è¡¨æ ¼å†…å®¹
                    key_patterns = [
                        r"(?:Asset|Portfolio|Investment).*?Mix",
                        r"(?:Cash Value|GCV|Surrender Value)",
                        r"(?:Death Benefit|Coverage)",
                        r"(?:Premium|Payment)",
                        r"(?:Fixed Income|Equity|Bond)",
                        r"å¹´åº¦.*?ç°é‡‘ä»·å€¼",
                        r"èµ„äº§.*?é…ç½®"
                    ]
                    
                    for pattern in key_patterns:
                        if re.search(pattern, text, re.IGNORECASE):
                            print(f"  ğŸ’¡ æ‰¾åˆ°å…³é”®è¯: {pattern}")
                            # æå–ä¸Šä¸‹æ–‡
                            match = re.search(pattern, text, re.IGNORECASE)
                            if match:
                                start = max(0, match.start() - 100)
                                end = min(len(text), match.end() + 300)
                                context = text[start:end].replace('\n', ' ')
                                results["potential_table_text"].append({
                                    "page": page_num + 1,
                                    "pattern": pattern,
                                    "context": context
                                })
                
                results["pages"].append(page_result)
                
    except Exception as e:
        print(f"é”™è¯¯: {e}")
        results["error"] = str(e)
    
    # æ€»ç»“
    print(f"\n{'='*60}")
    print("ğŸ“Š è¡¨æ ¼æå–æ€»ç»“:")
    print(f"  - æ ‡å‡†è¡¨æ ¼: {results['tables_found']} ä¸ª")
    print(f"  - æ–‡æœ¬è¡¨æ ¼: {results['text_tables_found']} ä¸ª")
    print(f"  - æ½œåœ¨è¡¨æ ¼å†…å®¹: {len(results['potential_table_text'])} å¤„")
    
    # å¦‚æœæ‰¾åˆ°æ½œåœ¨è¡¨æ ¼å†…å®¹ï¼Œæ˜¾ç¤ºè¯¦æƒ…
    if results["potential_table_text"]:
        print("\nğŸ“‹ æ½œåœ¨è¡¨æ ¼å†…å®¹ä½ç½®:")
        for item in results["potential_table_text"][:5]:
            print(f"  ç¬¬{item['page']}é¡µ - {item['pattern']}")
            print(f"    å†…å®¹: {item['context'][:150]}...")
    
    return results

def detect_text_tables(text):
    """æ£€æµ‹æ–‡æœ¬ä¸­çš„ä¼ªè¡¨æ ¼"""
    text_tables = []
    lines = text.split('\n')
    
    # æ¨¡å¼1: å†’å·åˆ†éš”çš„é”®å€¼å¯¹
    pattern1 = r'^([^:]{3,50}):\s*(.+)$'
    
    # æ¨¡å¼2: å¤šä¸ªç©ºæ ¼åˆ†éš”
    pattern2 = r'^(\S+)\s{2,}(\S+)(?:\s{2,}(\S+))?'
    
    # æ¨¡å¼3: åˆ¶è¡¨ç¬¦åˆ†éš”
    pattern3 = r'^([^\t]+)\t+(.+)$'
    
    # æ¨¡å¼4: ç™¾åˆ†æ¯”æˆ–é‡‘é¢
    pattern4 = r'([\w\s]+)\s+([\d,]+%?|USD[\d,]+|HKD[\d,]+)'
    
    consecutive_matches = []
    current_table = []
    
    for i, line in enumerate(lines):
        line = line.strip()
        if not line:
            if len(current_table) >= 2:
                text_tables.append({
                    "start_line": i - len(current_table),
                    "lines": current_table,
                    "pattern": "consecutive_structured",
                    "sample": '\n'.join(current_table[:3])
                })
            current_table = []
            continue
        
        # æ£€æŸ¥å„ç§æ¨¡å¼
        for pattern_name, pattern in [("colon", pattern1), ("spaces", pattern2), 
                                       ("tabs", pattern3), ("values", pattern4)]:
            if re.match(pattern, line):
                current_table.append(line)
                break
    
    # ç‰¹æ®Šæ¨¡å¼: Asset Allocationè¡¨æ ¼
    asset_pattern = r'(?:Fixed Income|Equity|Bond|Stock|Cash|Alternative).*?(\d+%?)'
    asset_matches = re.findall(asset_pattern, text, re.IGNORECASE | re.MULTILINE)
    if asset_matches:
        text_tables.append({
            "pattern": "asset_allocation",
            "matches": asset_matches,
            "sample": str(asset_matches)
        })
    
    return text_tables

def analyze_all_pdfs():
    """åˆ†ææ‰€æœ‰PDFæ–‡ä»¶"""
    pdf_files = [
        r"D:\æ¡Œé¢\RAG\ä¿é™©äº§å“\RoyalFortune_Product Brochure_EN.pdf",
        r"D:\æ¡Œé¢\RAG\ä¿é™©äº§å“\AIA FlexiAchieverSavingsPlan_tc-æ´»äº«å„²è“„è¨ˆåŠƒ.pdf"
    ]
    
    all_results = {}
    
    for pdf_file in pdf_files:
        if Path(pdf_file).exists():
            results = debug_table_extraction(pdf_file)
            all_results[Path(pdf_file).stem] = results
    
    # ä¿å­˜è°ƒè¯•ç»“æœ
    output_path = "output/table_debug_results.json"
    Path("output").mkdir(exist_ok=True)
    
    with open(output_path, 'w', encoding='utf-8') as f:
        json.dump(all_results, f, ensure_ascii=False, indent=2)
    
    print(f"\nè°ƒè¯•ç»“æœå·²ä¿å­˜åˆ°: {output_path}")
    
    return all_results

if __name__ == "__main__":
    analyze_all_pdfs()
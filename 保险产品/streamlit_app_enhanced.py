"""
ä¿é™©äº§å“RAGç³»ç»Ÿ - Streamlitå¢å¼ºç‰ˆ
å‚è€ƒweb_demo_enhanced.htmlå®ç°çš„åŠŸèƒ½å¢å¼ºç‰ˆæœ¬
"""
import streamlit as st
import os
from typing import List, Dict, Tuple
import json
import hashlib
from datetime import datetime
import pandas as pd
import time

# æ ¸å¿ƒåº“
import openai
from langchain.text_splitter import RecursiveCharacterTextSplitter
from langchain_openai import OpenAIEmbeddings, ChatOpenAI
from langchain_community.vectorstores import FAISS
from langchain.chains import RetrievalQA
import PyPDF2
import pdfplumber

# é¡µé¢é…ç½®
st.set_page_config(
    page_title="ä¿é™©äº§å“æ™ºèƒ½é—®ç­”ç³»ç»Ÿ",
    page_icon="ğŸ¥",
    layout="wide",
    initial_sidebar_state="expanded"
)

# è‡ªå®šä¹‰CSSæ ·å¼
st.markdown("""
<style>
    .main { padding: 0rem 1rem; }
    
    /* é—®é¢˜åˆ†ç±»æ ·å¼ */
    .category-header {
        background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
        color: white;
        padding: 0.8rem 1.2rem;
        border-radius: 10px;
        margin-bottom: 0.5rem;
        font-weight: bold;
    }
    
    .question-card {
        background: #f8f9fa;
        border-left: 4px solid #667eea;
        padding: 0.8rem;
        margin: 0.5rem 0;
        border-radius: 5px;
        cursor: pointer;
        transition: all 0.3s;
    }
    
    .question-card:hover {
        background: #e9ecef;
        transform: translateX(5px);
    }
    
    .answerable {
        color: #28a745;
    }
    
    .unanswerable {
        color: #dc3545;
        opacity: 0.7;
    }
    
    /* ç½®ä¿¡åº¦æ ‡ç­¾ */
    .confidence-high {
        background: #28a745;
        color: white;
        padding: 4px 12px;
        border-radius: 20px;
        font-size: 12px;
    }
    
    .confidence-medium {
        background: #ffc107;
        color: white;
        padding: 4px 12px;
        border-radius: 20px;
        font-size: 12px;
    }
    
    .confidence-low {
        background: #dc3545;
        color: white;
        padding: 4px 12px;
        border-radius: 20px;
        font-size: 12px;
    }
    
    /* ç­”æ¡ˆå¡ç‰‡ */
    .answer-card {
        background: #f0f9ff;
        border-radius: 10px;
        padding: 1.5rem;
        margin: 1rem 0;
    }
    
    /* æ¥æºä¿¡æ¯ */
    .source-card {
        background: white;
        border: 1px solid #dee2e6;
        border-radius: 8px;
        padding: 1rem;
        margin: 0.5rem 0;
    }
    
    /* å¿«é€Ÿé—®é¢˜æŒ‰é’® */
    .quick-question-btn {
        background: #f8f9fa;
        border: 1px solid #dee2e6;
        border-radius: 20px;
        padding: 0.5rem 1rem;
        margin: 0.25rem;
        transition: all 0.3s;
    }
    
    .quick-question-btn:hover {
        background: #667eea;
        color: white;
        border-color: #667eea;
    }
    
    /* ç»Ÿè®¡å¡ç‰‡ */
    .stat-card {
        background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
        color: white;
        padding: 1.2rem;
        border-radius: 10px;
        text-align: center;
    }
    
    .stat-value {
        font-size: 2rem;
        font-weight: bold;
    }
    
    .stat-label {
        font-size: 0.9rem;
        opacity: 0.9;
    }
</style>
""", unsafe_allow_html=True)

# åˆå§‹åŒ–session state
if 'vector_store' not in st.session_state:
    st.session_state.vector_store = None
if 'qa_history' not in st.session_state:
    st.session_state.qa_history = []
if 'documents' not in st.session_state:
    st.session_state.documents = []
if 'selected_question' not in st.session_state:
    st.session_state.selected_question = ""
if 'answer_confidence' not in st.session_state:
    st.session_state.answer_confidence = 0.0
if 'auto_submit' not in st.session_state:
    st.session_state.auto_submit = False
if 'active_tab' not in st.session_state:
    st.session_state.active_tab = 0

# é—®é¢˜åˆ†ç±»ç»“æ„
QUESTION_CATEGORIES = {
    "ğŸ“¦ äº§å“ä¿¡æ¯": {
        "questions": [
            ("ä¿é™©å…¬å¸åç§°", "What is the insurer entity name?", True),
            ("äº§å“åç§°", "What is the product name?", True),
            ("äº§å“èµ„äº§é…ç½®", "What is the product asset mix?", True),
            ("äº§å“ç±»å‹", "What is the product type?", True),
            ("å‘è¡Œåœ°åŒº", "What is the issuing jurisdiction?", True),
        ],
        "completion": "9/9"
    },
    "ğŸ“„ è®¡åˆ’è¯¦æƒ…": {
        "questions": [
            ("æœ€ä½ä¿è´¹", "What is the minimum premium?", True),
            ("æŠ•ä¿å¹´é¾„", "What is the issue age range?", True),
            ("ä¿å•è´§å¸", "What are the policy currencies?", True),
            ("ç¼´è´¹æœŸé™", "What are the premium terms?", True),
            ("èº«æ•…èµ”ä»˜ç‰¹ç‚¹", "What are the death settlement features?", True),
            ("è¢«ä¿é™©äººæ•°é‡", "Number of insured persons?", False),
            ("æ›´æ¢è¢«ä¿é™©äººåŠŸèƒ½", "Change of insured feature?", False),
        ],
        "completion": "9/11"
    },
    "ğŸ’° åˆ†çº¢å‹ç»ˆèº«å¯¿é™©": {
        "questions": [
            ("é¦–æ—¥ä¿è¯ç°é‡‘ä»·å€¼", "What is the Day 1 GCV?", True),
            ("é€€ä¿ä»·å€¼ç»„æˆ", "What are the surrender value components?", True),
            ("èº«æ•…èµ”ä»˜ç»„æˆ", "What are the death benefit components?", True),
        ],
        "completion": "3/3"
    },
    "â„¹ï¸ å…¶ä»–è¯¦æƒ…": {
        "questions": [
            ("åˆåŒé€‚ç”¨æ³•å¾‹", "What is the contract governing law?", True),
            ("å›æº¯å¯ç”¨æ€§", "Backtesting availability?", False),
            ("å…ä½“æ£€é™é¢", "Non-medical limits?", False),
            ("é™„åŠ ä¿éšœ", "Additional riders?", False),
        ],
        "completion": "1/4"
    },
    "ğŸ’¡ ç»¼åˆæ€§é—®é¢˜": {
        "questions": [
            ("äº§å“ä»‹ç»", "è¯·ä»‹ç»ä¸€ä¸‹RoyalFortuneäº§å“", True),
            ("ä¸»è¦ç‰¹ç‚¹", "What are the key features?", True),
            ("äº§å“ä¼˜åŠ¿", "RoyalFortuneçš„ä¼˜åŠ¿æ˜¯ä»€ä¹ˆï¼Ÿ", True),
            ("ä¿è¯ç°é‡‘ä»·å€¼æœºåˆ¶", "How does the guaranteed cash value work?", True),
        ],
        "completion": ""
    }
}

# çƒ­é—¨å¿«é€Ÿé—®é¢˜
HOT_QUESTIONS = [
    ("æœ€ä½ä¿è´¹", "RoyalFortuneçš„æœ€ä½ä¿è´¹æ˜¯å¤šå°‘ï¼Ÿ"),
    ("æŠ•ä¿å¹´é¾„", "æŠ•ä¿å¹´é¾„èŒƒå›´æ˜¯ä»€ä¹ˆï¼Ÿ"),
    ("ä¿è¯ç°é‡‘ä»·å€¼", "ä¿è¯ç°é‡‘ä»·å€¼æ˜¯å¤šå°‘ï¼Ÿ"),
    ("èº«æ•…èµ”ä»˜", "èº«æ•…èµ”ä»˜æœ‰å“ªäº›ç‰¹ç‚¹ï¼Ÿ"),
    ("äº§å“ä¼˜åŠ¿", "äº§å“çš„ä¼˜åŠ¿æ˜¯ä»€ä¹ˆï¼Ÿ"),
]

def initialize_openai():
    """åˆå§‹åŒ–OpenAIå®¢æˆ·ç«¯"""
    api_key = None
    
    # å°è¯•ä»å¤šä¸ªæ¥æºè·å–APIå¯†é’¥
    # 1. ä».envæ–‡ä»¶è¯»å–
    try:
        from dotenv import load_dotenv
        load_dotenv()
        api_key = os.getenv("OPENAI_API_KEY")
    except:
        pass
    
    # 2. ä»Streamlit secretsè·å–
    if not api_key:
        try:
            if hasattr(st, 'secrets') and "OPENAI_API_KEY" in st.secrets:
                api_key = st.secrets["OPENAI_API_KEY"]
        except Exception:
            pass
    
    # 3. ä»ç¯å¢ƒå˜é‡è·å–
    if not api_key:
        api_key = os.getenv("OPENAI_API_KEY")
    
    if api_key:
        openai.api_key = api_key
        os.environ["OPENAI_API_KEY"] = api_key
    
    return api_key

@st.cache_data
def process_pdf(uploaded_file) -> List[Dict]:
    """å¤„ç†PDFæ–‡ä»¶"""
    chunks = []
    try:
        # ä½¿ç”¨pdfplumberæå–æ–‡æœ¬
        with pdfplumber.open(uploaded_file) as pdf:
            text = ""
            for page_num, page in enumerate(pdf.pages, 1):
                page_text = page.extract_text() or ""
                text += f"\n[Page {page_num}]\n{page_text}\n"
                
                # æå–è¡¨æ ¼
                tables = page.extract_tables()
                for table in tables:
                    if table:
                        df = pd.DataFrame(table[1:], columns=table[0])
                        text += f"\n[Table on Page {page_num}]\n{df.to_string()}\n"
        
        # æ–‡æœ¬åˆ†å—
        text_splitter = RecursiveCharacterTextSplitter(
            chunk_size=800,
            chunk_overlap=200,
            separators=["\n\n", "\n", ".", ",", " ", ""]
        )
        
        chunks = text_splitter.split_text(text)
        return [{"content": chunk, "metadata": {"source": uploaded_file.name}} for chunk in chunks]
    
    except Exception as e:
        st.error(f"PDFå¤„ç†é”™è¯¯: {str(e)}")
        return []

def create_vector_store(documents: List[Dict]):
    """åˆ›å»ºå‘é‡å­˜å‚¨"""
    try:
        embeddings = OpenAIEmbeddings()
        texts = [doc["content"] for doc in documents]
        metadatas = [doc["metadata"] for doc in documents]
        
        vector_store = FAISS.from_texts(
            texts=texts,
            embedding=embeddings,
            metadatas=metadatas
        )
        return vector_store
    except Exception as e:
        st.error(f"åˆ›å»ºå‘é‡å­˜å‚¨å¤±è´¥: {str(e)}")
        return None

def answer_question_with_confidence(question: str, vector_store) -> Dict:
    """å›ç­”é—®é¢˜å¹¶è¿”å›ç½®ä¿¡åº¦"""
    try:
        # ç¡®ä¿APIå¯†é’¥å·²è®¾ç½®
        if not os.getenv("OPENAI_API_KEY"):
            return {
                "question": question,
                "answer": "è¯·å…ˆè®¾ç½®OpenAI APIå¯†é’¥",
                "sources": [],
                "confidence": 0.0,
                "timestamp": datetime.now().isoformat()
            }
        
        llm = ChatOpenAI(
            model_name="gpt-3.5-turbo",
            temperature=0.1,
            max_tokens=500
        )
        
        qa_chain = RetrievalQA.from_chain_type(
            llm=llm,
            chain_type="stuff",
            retriever=vector_store.as_retriever(
                search_kwargs={"k": 5}
            ),
            return_source_documents=True
        )
        
        # è®°å½•å¼€å§‹æ—¶é—´
        start_time = time.time()
        result = qa_chain({"query": question})
        response_time = time.time() - start_time
        
        # è·å–ç›¸å…³æ–‡æ¡£å¹¶è®¡ç®—ç½®ä¿¡åº¦
        source_documents = result.get("source_documents", [])
        
        # ç®€å•çš„ç½®ä¿¡åº¦è®¡ç®—ï¼ˆåŸºäºè¿”å›æ–‡æ¡£çš„ç›¸å…³æ€§ï¼‰
        confidence = 0.8 if source_documents else 0.3
        if len(source_documents) >= 3:
            confidence = 0.9
        elif len(source_documents) >= 2:
            confidence = 0.7
        
        # æ„å»ºæ¥æºä¿¡æ¯
        sources = []
        for doc in source_documents[:3]:
            sources.append({
                "doc_name": doc.metadata.get("source", "Unknown"),
                "content": doc.page_content[:200] + "...",
                "score": confidence  # ç®€åŒ–çš„åˆ†æ•°
            })
        
        return {
            "question": question,
            "answer": result["result"],
            "sources": sources,
            "confidence": confidence,
            "response_time": response_time,
            "timestamp": datetime.now().isoformat()
        }
    except Exception as e:
        return {
            "question": question,
            "answer": f"é”™è¯¯: {str(e)}",
            "sources": [],
            "confidence": 0.0,
            "response_time": 0,
            "timestamp": datetime.now().isoformat()
        }

def display_confidence_badge(confidence: float):
    """æ˜¾ç¤ºç½®ä¿¡åº¦æ ‡ç­¾"""
    percentage = confidence * 100
    if confidence >= 0.7:
        badge_class = "confidence-high"
        emoji = "âœ…"
    elif confidence >= 0.3:
        badge_class = "confidence-medium"
        emoji = "âš ï¸"
    else:
        badge_class = "confidence-low"
        emoji = "âŒ"
    
    st.markdown(
        f'<span class="{badge_class}">{emoji} ç½®ä¿¡åº¦: {percentage:.1f}%</span>',
        unsafe_allow_html=True
    )

# ä¸»ç•Œé¢
st.title("ğŸ¤– ä¿é™©äº§å“æ™ºèƒ½é—®ç­”ç³»ç»Ÿ")
st.markdown("### åŸºäºRAGæŠ€æœ¯çš„ä¼ä¸šçº§PoCæ¼”ç¤º | æ”¯æŒä¸­è‹±æ–‡æ™ºèƒ½é—®ç­”")

# é¡¶éƒ¨ç»Ÿè®¡ä¿¡æ¯
col1, col2, col3, col4 = st.columns(4)
with col1:
    st.markdown("""
    <div class="stat-card">
        <div class="stat-value">{}</div>
        <div class="stat-label">æ–‡æ¡£æ•°</div>
    </div>
    """.format(len(set([doc["metadata"]["source"] for doc in st.session_state.documents])) if st.session_state.documents else 0),
    unsafe_allow_html=True)

with col2:
    st.markdown("""
    <div class="stat-card">
        <div class="stat-value">{}</div>
        <div class="stat-label">åˆ†å—æ•°</div>
    </div>
    """.format(len(st.session_state.documents)),
    unsafe_allow_html=True)

with col3:
    st.markdown("""
    <div class="stat-card">
        <div class="stat-value">81.5%</div>
        <div class="stat-label">å›ç­”ç‡</div>
    </div>
    """, unsafe_allow_html=True)

with col4:
    st.markdown("""
    <div class="stat-card">
        <div class="stat-value">{}</div>
        <div class="stat-label">å†å²é—®ç­”</div>
    </div>
    """.format(len(st.session_state.qa_history)),
    unsafe_allow_html=True)

# ä¾§è¾¹æ 
with st.sidebar:
    st.header("âš™ï¸ ç³»ç»Ÿé…ç½®")
    
    # APIå¯†é’¥è¾“å…¥
    api_key = initialize_openai()
    if not api_key:
        api_key_input = st.text_input(
            "OpenAI API Key",
            type="password",
            help="è¯·è¾“å…¥æ‚¨çš„OpenAI APIå¯†é’¥"
        )
        if api_key_input:
            os.environ["OPENAI_API_KEY"] = api_key_input
            st.success("âœ… APIå¯†é’¥å·²è®¾ç½®")
            st.rerun()
    else:
        st.success("âœ… APIå¯†é’¥å·²é…ç½®")
    
    st.divider()
    
    # æ–‡ä»¶ä¸Šä¼ 
    st.header("ğŸ“„ æ–‡æ¡£ç®¡ç†")
    uploaded_files = st.file_uploader(
        "é€‰æ‹©PDFæ–‡ä»¶",
        type=["pdf"],
        accept_multiple_files=True,
        help="æ”¯æŒä¸Šä¼ å¤šä¸ªPDFæ–‡ä»¶"
    )
    
    if uploaded_files:
        # æ˜¾ç¤ºå·²ä¸Šä¼ çš„æ–‡ä»¶
        st.info(f"å·²é€‰æ‹© {len(uploaded_files)} ä¸ªæ–‡ä»¶")
        for file in uploaded_files:
            st.text(f"ğŸ“„ {file.name} ({file.size/1024/1024:.2f}MB)")
        
        # å¤„ç†æ–‡æ¡£æŒ‰é’® - å§‹ç»ˆæ˜¾ç¤º
        if st.button("ğŸ”„ å¤„ç†æ–‡æ¡£", use_container_width=True, type="primary", key="process_docs"):
            if not api_key:
                st.error("âŒ è¯·å…ˆè®¾ç½®OpenAI APIå¯†é’¥")
            else:
                with st.spinner("æ­£åœ¨å¤„ç†PDFæ–‡æ¡£..."):
                    all_documents = []
                    progress = st.progress(0)
                    
                    for i, file in enumerate(uploaded_files):
                        docs = process_pdf(file)
                        all_documents.extend(docs)
                        progress.progress((i + 1) / len(uploaded_files))
                    
                    if all_documents:
                        st.session_state.documents = all_documents
                        with st.spinner("æ­£åœ¨åˆ›å»ºå‘é‡æ•°æ®åº“..."):
                            st.session_state.vector_store = create_vector_store(all_documents)
                        st.success(f"âœ… æˆåŠŸå¤„ç† {len(uploaded_files)} ä¸ªæ–‡ä»¶ï¼Œå…± {len(all_documents)} ä¸ªæ–‡æœ¬å—")
                        st.balloons()  # æ·»åŠ åº†ç¥åŠ¨ç”»
    
    # å·²ä¸Šä¼ æ–‡æ¡£åˆ—è¡¨
    if st.session_state.documents:
        st.divider()
        st.header("ğŸ“š å·²ä¸Šä¼ æ–‡æ¡£")
        doc_sources = list(set([doc["metadata"]["source"] for doc in st.session_state.documents]))
        for doc_name in doc_sources:
            doc_chunks = [d for d in st.session_state.documents if d["metadata"]["source"] == doc_name]
            st.info(f"ğŸ“„ {doc_name}\n\n{len(doc_chunks)} ä¸ªåˆ†å—")
    
    # ç³»ç»ŸçŠ¶æ€
    st.divider()
    st.header("âš¡ ç³»ç»ŸçŠ¶æ€")
    status_col1, status_col2 = st.columns(2)
    with status_col1:
        st.metric("APIçŠ¶æ€", "âœ… åœ¨çº¿" if api_key else "âŒ ç¦»çº¿")
    with status_col2:
        st.metric("å‘é‡åº“", "âœ… å°±ç»ª" if st.session_state.vector_store else "âš ï¸ æœªå°±ç»ª")
    
    # æ¸…é™¤å†å²
    if st.button("ğŸ—‘ï¸ æ¸…é™¤å†å²", use_container_width=True):
        st.session_state.qa_history = []
        st.session_state.selected_question = ""
        st.rerun()

# ä¸»è¦å†…å®¹åŒºåŸŸ
if st.session_state.vector_store:
    # åˆ›å»ºæ ‡ç­¾é¡µ
    tab1, tab2, tab3, tab4 = st.tabs(["ğŸ’¬ æ™ºèƒ½é—®ç­”", "ğŸ“‹ é—®é¢˜åˆ†ç±»", "ğŸ“Š æ‰¹é‡é—®ç­”", "ğŸ“œ å†å²è®°å½•"])
    
    # æ™ºèƒ½é—®ç­”æ ‡ç­¾é¡µ
    with tab1:
        # å¦‚æœæ˜¯ä»é—®é¢˜åˆ†ç±»è·³è½¬è¿‡æ¥çš„ï¼Œæ˜¾ç¤ºæç¤º
        if st.session_state.auto_submit and st.session_state.selected_question:
            st.info(f"ğŸ’¡ å·²é€‰æ‹©é—®é¢˜ï¼š{st.session_state.selected_question[:50]}...")
            # è‡ªåŠ¨æ‰§è¡Œé—®ç­”
            with st.spinner("ğŸ¤” æ­£åœ¨ä¸ºæ‚¨è§£ç­”..."):
                result = answer_question_with_confidence(st.session_state.selected_question, st.session_state.vector_store)
                st.session_state.qa_history.insert(0, result)
                st.session_state.answer_confidence = result["confidence"]
                st.session_state.auto_submit = False  # é‡ç½®æ ‡å¿—
            
            # æ˜¾ç¤ºç­”æ¡ˆ
            st.markdown("---")
            
            # ç­”æ¡ˆå¤´éƒ¨
            answer_col1, answer_col2 = st.columns([3, 1])
            with answer_col1:
                st.markdown("### ğŸ“ AIå›ç­”")
            with answer_col2:
                display_confidence_badge(result["confidence"])
            
            # ç­”æ¡ˆå†…å®¹
            st.markdown(f"""
            <div class="answer-card">
                {result["answer"]}
            </div>
            """, unsafe_allow_html=True)
            
            # å“åº”æ—¶é—´
            if "response_time" in result:
                st.caption(f"â±ï¸ å“åº”æ—¶é—´: {result['response_time']:.2f}ç§’")
            
            # æ˜¾ç¤ºæ¥æº
            if result["sources"]:
                st.markdown("### ğŸ“š ä¿¡æ¯æ¥æº")
                for i, source in enumerate(result["sources"], 1):
                    with st.expander(f"æ¥æº {i}: {source['doc_name']}", expanded=False):
                        st.write(source["content"])
                        st.caption(f"ç›¸å…³åº¦: {source['score']:.2f}")
            
            st.divider()
        
        # çƒ­é—¨å¿«é€Ÿé—®é¢˜
        st.markdown("#### ğŸ”¥ çƒ­é—¨é—®é¢˜")
        cols = st.columns(len(HOT_QUESTIONS))
        for i, (label, question) in enumerate(HOT_QUESTIONS):
            with cols[i]:
                if st.button(label, key=f"hot_{i}", use_container_width=True):
                    st.session_state.selected_question = question
                    st.session_state.auto_submit = True
                    st.rerun()
        
        st.divider()
        
        # é—®é¢˜è¾“å…¥
        col1, col2 = st.columns([4, 1])
        with col1:
            question = st.text_input(
                "è¾“å…¥æ‚¨çš„é—®é¢˜ï¼ˆæ”¯æŒä¸­è‹±æ–‡ï¼‰",
                value=st.session_state.selected_question if not st.session_state.auto_submit else "",
                placeholder="ä¾‹å¦‚: What is the minimum premium?",
                key="question_input"
            )
        with col2:
            submit_button = st.button("ğŸ” æé—®", type="primary", use_container_width=True)
        
        # æäº¤é—®é¢˜
        if submit_button and question:
            with st.spinner("ğŸ¤” æ­£åœ¨æ€è€ƒä¸­..."):
                result = answer_question_with_confidence(question, st.session_state.vector_store)
                st.session_state.qa_history.insert(0, result)
                st.session_state.answer_confidence = result["confidence"]
            
            # æ˜¾ç¤ºç­”æ¡ˆ
            st.markdown("---")
            
            # ç­”æ¡ˆå¤´éƒ¨
            answer_col1, answer_col2 = st.columns([3, 1])
            with answer_col1:
                st.markdown("### ğŸ“ AIå›ç­”")
            with answer_col2:
                display_confidence_badge(result["confidence"])
            
            # ç­”æ¡ˆå†…å®¹
            st.markdown(f"""
            <div class="answer-card">
                {result["answer"]}
            </div>
            """, unsafe_allow_html=True)
            
            # å“åº”æ—¶é—´
            if "response_time" in result:
                st.caption(f"â±ï¸ å“åº”æ—¶é—´: {result['response_time']:.2f}ç§’")
            
            # æ˜¾ç¤ºæ¥æº
            if result["sources"]:
                st.markdown("### ğŸ“š ä¿¡æ¯æ¥æº")
                for i, source in enumerate(result["sources"], 1):
                    with st.expander(f"æ¥æº {i}: {source['doc_name']}", expanded=False):
                        st.write(source["content"])
                        st.caption(f"ç›¸å…³åº¦: {source['score']:.2f}")
    
    # é—®é¢˜åˆ†ç±»æ ‡ç­¾é¡µ
    with tab2:
        st.markdown("### ğŸ“‹ å¯å›ç­”é—®é¢˜åˆ—è¡¨")
        st.success("ğŸ’¡ **ç‚¹å‡»é—®é¢˜åä¼šè‡ªåŠ¨è·³è½¬åˆ°æ™ºèƒ½é—®ç­”é¡µé¢å¹¶è·å–ç­”æ¡ˆï¼**")
        st.info("âœ… è¡¨ç¤ºå¯å›ç­”çš„é—®é¢˜ï¼ŒâŒ è¡¨ç¤ºéœ€è¦æ›´å¤šæ–‡æ¡£æ”¯æŒã€‚")
        
        for category_name, category_data in QUESTION_CATEGORIES.items():
            # åˆ†ç±»æ ‡é¢˜
            st.markdown(f"""
            <div class="category-header">
                {category_name} {category_data['completion']}
            </div>
            """, unsafe_allow_html=True)
            
            # é—®é¢˜åˆ—è¡¨
            for cn_name, en_question, is_answerable in category_data["questions"]:
                col1, col2 = st.columns([4, 1])
                with col1:
                    if is_answerable:
                        button_label = f"âœ… {cn_name}"
                        help_text = f"ç‚¹å‡»æŸ¥çœ‹: {en_question}"
                        if st.button(button_label, key=f"cat_{en_question}", 
                                   use_container_width=True, 
                                   help=help_text):
                            # è®¾ç½®é€‰ä¸­çš„é—®é¢˜å¹¶æ ‡è®°éœ€è¦è‡ªåŠ¨æäº¤
                            st.session_state.selected_question = en_question
                            st.session_state.auto_submit = True
                            st.rerun()
                    else:
                        st.button(f"âŒ {cn_name}", 
                                key=f"cat_{en_question}", 
                                use_container_width=True, 
                                disabled=True,
                                help="éœ€è¦æ›´å¤šæ–‡æ¡£æ”¯æŒ")
                with col2:
                    if is_answerable:
                        st.markdown('<span style="color: #28a745;">â†’ ç‚¹å‡»æé—®</span>', 
                                  unsafe_allow_html=True)
                    else:
                        st.markdown('<span style="color: #dc3545;">ä¸å¯ç”¨</span>', 
                                  unsafe_allow_html=True)
    
    # æ‰¹é‡é—®ç­”æ ‡ç­¾é¡µ
    with tab3:
        st.markdown("### ğŸš€ æ‰¹é‡å›ç­”é¢„è®¾é—®é¢˜")
        st.info("ç³»ç»Ÿå°†è‡ªåŠ¨å›ç­”æ‰€æœ‰å¯å›ç­”çš„é¢„è®¾é—®é¢˜ï¼Œå¹¶ç”Ÿæˆå®Œæ•´æŠ¥å‘Šã€‚")
        
        if st.button("å¼€å§‹æ‰¹é‡é—®ç­”", type="primary", use_container_width=True):
            # æ”¶é›†æ‰€æœ‰å¯å›ç­”çš„é—®é¢˜
            all_questions = []
            for category_data in QUESTION_CATEGORIES.values():
                for cn_name, en_question, is_answerable in category_data["questions"]:
                    if is_answerable:
                        all_questions.append((cn_name, en_question))
            
            # æ‰¹é‡å¤„ç†
            progress = st.progress(0)
            status = st.empty()
            results = []
            
            for i, (cn_name, question) in enumerate(all_questions):
                status.text(f"æ­£åœ¨å¤„ç†: {cn_name} ({i+1}/{len(all_questions)})")
                result = answer_question_with_confidence(question, st.session_state.vector_store)
                results.append(result)
                st.session_state.qa_history.insert(0, result)
                progress.progress((i + 1) / len(all_questions))
            
            # æ˜¾ç¤ºç»“æœ
            st.success(f"âœ… å·²å®Œæˆ {len(all_questions)} ä¸ªé—®é¢˜çš„å›ç­”")
            
            # ç”ŸæˆæŠ¥å‘Š
            st.markdown("### ğŸ“Š æ‰¹é‡é—®ç­”æŠ¥å‘Š")
            for i, result in enumerate(results, 1):
                with st.expander(f"é—®é¢˜ {i}: {result['question'][:50]}...", expanded=False):
                    col1, col2 = st.columns([3, 1])
                    with col1:
                        st.markdown(f"**ç­”æ¡ˆ:** {result['answer']}")
                    with col2:
                        display_confidence_badge(result['confidence'])
                    
                    if result['sources']:
                        st.caption(f"æ¥æº: {', '.join([s['doc_name'] for s in result['sources']])}")
    
    # å†å²è®°å½•æ ‡ç­¾é¡µ
    with tab4:
        st.markdown("### ğŸ“œ é—®ç­”å†å²")
        
        if st.session_state.qa_history:
            # å¯¼å‡ºæŒ‰é’®
            col1, col2 = st.columns(2)
            with col1:
                # è½¬æ¢ä¸ºDataFrame
                df = pd.DataFrame(st.session_state.qa_history)
                csv = df.to_csv(index=False)
                st.download_button(
                    label="ğŸ“¥ å¯¼å‡ºCSV",
                    data=csv,
                    file_name=f"qa_results_{datetime.now().strftime('%Y%m%d_%H%M%S')}.csv",
                    mime="text/csv",
                    use_container_width=True
                )
            
            with col2:
                # JSONå¯¼å‡º
                json_str = json.dumps(st.session_state.qa_history, ensure_ascii=False, indent=2)
                st.download_button(
                    label="ğŸ“¥ å¯¼å‡ºJSON",
                    data=json_str,
                    file_name=f"qa_results_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json",
                    mime="application/json",
                    use_container_width=True
                )
            
            st.divider()
            
            # æ˜¾ç¤ºå†å²è®°å½•
            for i, item in enumerate(st.session_state.qa_history[:20]):  # æ˜¾ç¤ºæœ€è¿‘20æ¡
                with st.expander(f"â“ {item['question'][:100]}...", expanded=False):
                    col1, col2 = st.columns([3, 1])
                    with col1:
                        st.markdown(f"**ç­”æ¡ˆ:**\n{item['answer']}")
                    with col2:
                        if 'confidence' in item:
                            display_confidence_badge(item['confidence'])
                    
                    if item.get('sources'):
                        st.markdown("**æ¥æº:**")
                        for source in item['sources']:
                            st.caption(f"â€¢ {source['doc_name']}")
                    
                    st.caption(f"â° æ—¶é—´: {item['timestamp']}")
        else:
            st.info("æš‚æ— å†å²è®°å½•")

else:
    # æ¬¢è¿é¡µé¢
    st.info("ğŸ‘† è¯·å…ˆåœ¨ä¾§è¾¹æ ä¸Šä¼ PDFæ–‡æ¡£å¼€å§‹ä½¿ç”¨")
    
    # ä½¿ç”¨è¯´æ˜
    with st.expander("ğŸ“– ä½¿ç”¨è¯´æ˜", expanded=True):
        st.markdown("""
        ### ğŸš€ å¿«é€Ÿå¼€å§‹
        1. **é…ç½®APIå¯†é’¥**: åœ¨ä¾§è¾¹æ è¾“å…¥OpenAI APIå¯†é’¥
        2. **ä¸Šä¼ æ–‡æ¡£**: é€‰æ‹©ä¿é™©äº§å“PDFæ–‡ä»¶
        3. **å¤„ç†æ–‡æ¡£**: ç‚¹å‡»"å¤„ç†æ–‡æ¡£"æŒ‰é’®
        4. **å¼€å§‹æé—®**: é€šè¿‡ä»¥ä¸‹æ–¹å¼æé—®ï¼š
           - ç‚¹å‡»çƒ­é—¨é—®é¢˜å¿«é€Ÿæé—®
           - åœ¨é—®é¢˜åˆ†ç±»ä¸­é€‰æ‹©é¢„è®¾é—®é¢˜
           - è‡ªå®šä¹‰è¾“å…¥é—®é¢˜
        5. **æŸ¥çœ‹ç»“æœ**: ç³»ç»Ÿä¼šæ˜¾ç¤ºç­”æ¡ˆã€ç½®ä¿¡åº¦å’Œæ¥æºä¿¡æ¯
        
        ### âœ¨ åŠŸèƒ½ç‰¹ç‚¹
        - âœ… **æ™ºèƒ½é—®ç­”**: æ”¯æŒä¸­è‹±æ–‡æ··åˆæŸ¥è¯¢
        - âœ… **é—®é¢˜åˆ†ç±»**: ç»“æ„åŒ–çš„é—®é¢˜åˆ†ç±»ä½“ç³»
        - âœ… **ç½®ä¿¡åº¦è¯„ä¼°**: æ¯ä¸ªç­”æ¡ˆéƒ½æœ‰ç½®ä¿¡åº¦è¯„åˆ†
        - âœ… **æ¥æºè¿½è¸ª**: æ˜¾ç¤ºç­”æ¡ˆçš„æ–‡æ¡£æ¥æº
        - âœ… **æ‰¹é‡é—®ç­”**: ä¸€é”®å›ç­”æ‰€æœ‰é¢„è®¾é—®é¢˜
        - âœ… **å†å²è®°å½•**: ä¿å­˜æ‰€æœ‰é—®ç­”å†å²
        - âœ… **æ•°æ®å¯¼å‡º**: æ”¯æŒCSVå’ŒJSONæ ¼å¼å¯¼å‡º
        
        ### ğŸ¯ æœ€ä½³å®è·µ
        - ä½¿ç”¨é¢„è®¾é—®é¢˜è·å¾—æœ€å‡†ç¡®çš„ç­”æ¡ˆ
        - å…³æ³¨ç½®ä¿¡åº¦è¯„åˆ†ï¼ˆ>70%ä¸ºé«˜è´¨é‡ç­”æ¡ˆï¼‰
        - æŸ¥çœ‹æ¥æºä¿¡æ¯éªŒè¯ç­”æ¡ˆå‡†ç¡®æ€§
        - å®šæœŸå¯¼å‡ºå†å²è®°å½•å¤‡ä»½æ•°æ®
        
        ### âš ï¸ æ³¨æ„äº‹é¡¹
        - è¯·ç¡®ä¿PDFæ–‡ä»¶å°äº10MB
        - APIè°ƒç”¨ä¼šäº§ç”Ÿè´¹ç”¨
        - ç½®ä¿¡åº¦ä½çš„ç­”æ¡ˆéœ€è¦äººå·¥éªŒè¯
        """)

# é¡µè„š
st.divider()
col1, col2, col3 = st.columns(3)
with col1:
    st.caption("ğŸ”’ æ•°æ®å®‰å…¨")
with col2:
    st.caption("ğŸ“§ æŠ€æœ¯æ”¯æŒ")
with col3:
    st.caption("v2.0.0 å¢å¼ºç‰ˆ")
"""
ä¿é™©äº§å“RAGç³»ç»Ÿ - è‡ªå®šä¹‰å¯¼èˆªç‰ˆæœ¬
è§£å†³æ ‡ç­¾é¡µè·³è½¬é—®é¢˜
"""
import streamlit as st
import os
from typing import List, Dict
import json
from datetime import datetime
import pandas as pd
import time
import logging
import sys

# é…ç½®æ—¥å¿—
logging.basicConfig(
    level=logging.INFO,  # æ”¹ä¸ºINFOçº§åˆ«ï¼Œå¤§å¹…æå‡æ€§èƒ½
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
    handlers=[
        logging.StreamHandler(sys.stdout),
        logging.FileHandler('rag_debug.log', encoding='utf-8')
    ]
)

# ç‰¹åˆ«ç¦ç”¨pdfminerçš„è°ƒè¯•æ—¥å¿—ï¼ˆè¿™æ˜¯æ€§èƒ½æ€æ‰‹ï¼ï¼‰
logging.getLogger('pdfminer').setLevel(logging.WARNING)
logging.getLogger('pdfplumber').setLevel(logging.WARNING)
logger = logging.getLogger(__name__)

# æ ¸å¿ƒåº“
import openai
from langchain.text_splitter import RecursiveCharacterTextSplitter
from langchain_openai import OpenAIEmbeddings, ChatOpenAI
from langchain_community.vectorstores import FAISS
from langchain.chains import RetrievalQA
import PyPDF2
import pdfplumber
# å¯¼å…¥æ”¹è¿›çš„PDFå¤„ç†å™¨å’Œè¯Šæ–­å·¥å…·
from pdf_processor_improved import process_pdf_with_timeout, check_dependencies
from pdf_processor_fast import process_pdf_fast, process_pdf_parallel  # å¯¼å…¥å¿«é€Ÿå¤„ç†å™¨
from pdf_diagnostic import diagnose_pdf, display_pdf_diagnosis, should_process_pdf, get_processing_timeout

# é¡µé¢é…ç½®
st.set_page_config(
    page_title="ä¿é™©äº§å“æ™ºèƒ½é—®ç­”ç³»ç»Ÿ",
    page_icon="ğŸ¥",
    layout="wide",
    initial_sidebar_state="expanded"
)

# è‡ªå®šä¹‰CSSæ ·å¼
st.markdown("""
<style>
    .nav-button {
        display: inline-block;
        padding: 0.5rem 1rem;
        margin: 0.2rem;
        background: #f0f2f6;
        border-radius: 8px;
        text-align: center;
        cursor: pointer;
        transition: all 0.3s;
    }
    
    .nav-button:hover {
        background: #667eea;
        color: white;
    }
    
    .nav-button.active {
        background: #667eea;
        color: white;
        font-weight: bold;
    }
    
    .question-card {
        background: #f8f9fa;
        border-left: 4px solid #667eea;
        padding: 0.8rem;
        margin: 0.5rem 0;
        border-radius: 5px;
    }
    
    .confidence-high {
        background: #28a745;
        color: white;
        padding: 4px 12px;
        border-radius: 20px;
        font-size: 12px;
    }
    
    .confidence-medium {
        background: #ffc107;
        color: white;
        padding: 4px 12px;
        border-radius: 20px;
        font-size: 12px;
    }
    
    .confidence-low {
        background: #dc3545;
        color: white;
        padding: 4px 12px;
        border-radius: 20px;
        font-size: 12px;
    }
    
    .answer-card {
        background: #f0f9ff;
        border-radius: 10px;
        padding: 1.5rem;
        margin: 1rem 0;
    }
    
    .category-header {
        background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
        color: white;
        padding: 0.8rem 1.2rem;
        border-radius: 10px;
        margin-bottom: 0.5rem;
        font-weight: bold;
    }
</style>
""", unsafe_allow_html=True)

# åˆå§‹åŒ–session state
if 'current_page' not in st.session_state:
    st.session_state.current_page = "æ™ºèƒ½é—®ç­”"
if 'vector_store' not in st.session_state:
    st.session_state.vector_store = None
if 'qa_history' not in st.session_state:
    st.session_state.qa_history = []
if 'documents' not in st.session_state:
    st.session_state.documents = []
if 'selected_question' not in st.session_state:
    st.session_state.selected_question = ""
if 'auto_submit' not in st.session_state:
    st.session_state.auto_submit = False
if 'last_answer' not in st.session_state:
    st.session_state.last_answer = None

# é—®é¢˜åˆ†ç±»ç»“æ„
QUESTION_CATEGORIES = {
    "ğŸ“¦ äº§å“ä¿¡æ¯": {
        "questions": [
            ("ä¿é™©å…¬å¸åç§°", "What is the insurer entity name?", True),
            ("äº§å“åç§°", "What is the product name?", True),
            ("äº§å“èµ„äº§é…ç½®", "What is the product asset mix?", True),
            ("äº§å“ç±»å‹", "What is the product type?", True),
            ("å‘è¡Œåœ°åŒº", "What is the issuing jurisdiction?", True),
        ],
        "completion": "9/9"
    },
    "ğŸ“„ è®¡åˆ’è¯¦æƒ…": {
        "questions": [
            ("æœ€ä½ä¿è´¹", "What is the minimum premium?", True),
            ("æŠ•ä¿å¹´é¾„", "What is the issue age range?", True),
            ("ä¿å•è´§å¸", "What are the policy currencies?", True),
            ("ç¼´è´¹æœŸé™", "What are the premium terms?", True),
            ("èº«æ•…èµ”ä»˜ç‰¹ç‚¹", "What are the death settlement features?", True),
        ],
        "completion": "9/11"
    },
    "ğŸ’° åˆ†çº¢å‹ç»ˆèº«å¯¿é™©": {
        "questions": [
            ("é¦–æ—¥ä¿è¯ç°é‡‘ä»·å€¼", "What is the Day 1 GCV?", True),
            ("é€€ä¿ä»·å€¼ç»„æˆ", "What are the surrender value components?", True),
            ("èº«æ•…èµ”ä»˜ç»„æˆ", "What are the death benefit components?", True),
        ],
        "completion": "3/3"
    }
}

# çƒ­é—¨å¿«é€Ÿé—®é¢˜
HOT_QUESTIONS = [
    ("æœ€ä½ä¿è´¹", "RoyalFortuneçš„æœ€ä½ä¿è´¹æ˜¯å¤šå°‘ï¼Ÿ"),
    ("æŠ•ä¿å¹´é¾„", "æŠ•ä¿å¹´é¾„èŒƒå›´æ˜¯ä»€ä¹ˆï¼Ÿ"),
    ("ä¿è¯ç°é‡‘ä»·å€¼", "ä¿è¯ç°é‡‘ä»·å€¼æ˜¯å¤šå°‘ï¼Ÿ"),
    ("èº«æ•…èµ”ä»˜", "èº«æ•…èµ”ä»˜æœ‰å“ªäº›ç‰¹ç‚¹ï¼Ÿ"),
]

def initialize_openai():
    """åˆå§‹åŒ–OpenAIå®¢æˆ·ç«¯"""
    api_key = None
    
    # ä».envæ–‡ä»¶è¯»å–
    try:
        from dotenv import load_dotenv
        load_dotenv()
        api_key = os.getenv("OPENAI_API_KEY")
    except:
        pass
    
    if api_key:
        openai.api_key = api_key
        os.environ["OPENAI_API_KEY"] = api_key
    
    return api_key

@st.cache_data
def process_pdf(uploaded_file) -> List[Dict]:
    """å¤„ç†PDFæ–‡ä»¶"""
    chunks = []
    try:
        logger.info(f"å¼€å§‹å¤„ç†PDFæ–‡ä»¶: {uploaded_file.name}")
        
        with pdfplumber.open(uploaded_file) as pdf:
            text = ""
            empty_pages = 0
            total_pages = len(pdf.pages)
            logger.info(f"PDFæ€»é¡µæ•°: {total_pages}")
            
            for page_num, page in enumerate(pdf.pages, 1):
                page_text = page.extract_text() or ""
                text_length = len(page_text.strip())
                logger.debug(f"ç¬¬ {page_num} é¡µæå–æ–‡æœ¬é•¿åº¦: {text_length}")
                
                # ç»Ÿè®¡ç©ºé¡µé¢
                if not page_text.strip():
                    empty_pages += 1
                    logger.warning(f"ç¬¬ {page_num} é¡µæœªæå–åˆ°æ–‡æœ¬å†…å®¹")
                    st.warning(f"âš ï¸ ç¬¬ {page_num} é¡µæœªæå–åˆ°æ–‡æœ¬å†…å®¹")
                else:
                    # æ˜¾ç¤ºå‰100ä¸ªå­—ç¬¦ä½œä¸ºé¢„è§ˆ
                    preview = page_text[:100].replace('\n', ' ')
                    logger.info(f"ç¬¬ {page_num} é¡µæ–‡æœ¬é¢„è§ˆ: {preview}...")
                
                text += f"\n[Page {page_num}]\n{page_text}\n"
                
                # æå–è¡¨æ ¼
                tables = page.extract_tables()
                if tables:
                    logger.info(f"ç¬¬ {page_num} é¡µå‘ç° {len(tables)} ä¸ªè¡¨æ ¼")
                for table_idx, table in enumerate(tables):
                    if table:
                        df = pd.DataFrame(table[1:], columns=table[0])
                        logger.debug(f"è¡¨æ ¼ {table_idx+1} å¤§å°: {df.shape}")
                        text += f"\n[Table on Page {page_num}]\n{df.to_string()}\n"
            
            # æ˜¾ç¤ºæå–ç»Ÿè®¡
            logger.info(f"æ–‡æ¡£æå–å®Œæˆ - æ€»æ–‡æœ¬é•¿åº¦: {len(text)}, ç©ºé¡µé¢: {empty_pages}/{total_pages}")
            
            if empty_pages > 0:
                st.warning(f"ğŸ“Š æ–‡æ¡£æå–ç»Ÿè®¡: æ€»é¡µæ•° {total_pages}, ç©ºé¡µé¢ {empty_pages}, æœ‰æ•ˆé¡µé¢ {total_pages - empty_pages}")
            
            # æ£€æŸ¥æ˜¯å¦æå–åˆ°æœ‰æ•ˆå†…å®¹
            if not text.strip():
                logger.error("æœªèƒ½ä»PDFä¸­æå–åˆ°ä»»ä½•æ–‡æœ¬å†…å®¹")
                st.error("âŒ æœªèƒ½ä»PDFä¸­æå–åˆ°ä»»ä½•æ–‡æœ¬å†…å®¹ï¼Œè¯·æ£€æŸ¥PDFæ˜¯å¦ä¸ºæ‰«æç‰ˆ")
                return []
        
        # ä½¿ç”¨æ›´å°çš„chunk_sizeå’Œæ›´å¤§çš„overlapä»¥ä¿æŒä¸Šä¸‹æ–‡å®Œæ•´æ€§
        text_splitter = RecursiveCharacterTextSplitter(
            chunk_size=1000,  # å¢åŠ åˆ°1000
            chunk_overlap=300,  # å¢åŠ åˆ°300
            separators=["\n\n", "\n", "ã€‚", "ï¼", "ï¼Ÿ", ".", "!", "?", " ", ""]
        )
        
        chunks = text_splitter.split_text(text)
        logger.info(f"æ–‡æœ¬åˆ†å—å®Œæˆ: ç”Ÿæˆ {len(chunks)} ä¸ªchunks")
        
        # è¿‡æ»¤æ‰è¿‡çŸ­çš„chunks
        valid_chunks = [chunk for chunk in chunks if len(chunk.strip()) > 50]
        logger.info(f"æœ‰æ•ˆchunks: {len(valid_chunks)}/{len(chunks)}")
        
        # è®°å½•å‰3ä¸ªchunksä½œä¸ºç¤ºä¾‹
        for i, chunk in enumerate(valid_chunks[:3]):
            logger.debug(f"Chunk {i} é¢„è§ˆ: {chunk[:100]}...")
        
        st.info(f"ğŸ“„ æ–‡æœ¬åˆ†å—: åŸå§‹ {len(chunks)} å—, æœ‰æ•ˆ {len(valid_chunks)} å—")
        
        return [{"content": chunk, "metadata": {"source": uploaded_file.name, "chunk_index": i}} 
                for i, chunk in enumerate(valid_chunks)]
    
    except Exception as e:
        logger.exception(f"PDFå¤„ç†é”™è¯¯: {str(e)}")
        st.error(f"PDFå¤„ç†é”™è¯¯: {str(e)}")
        st.error("ğŸ’¡ æç¤º: å¦‚æœæ˜¯æ‰«æç‰ˆPDFï¼Œè¯·å°è¯•ä½¿ç”¨OCRå·¥å…·å…ˆè½¬æ¢ä¸ºæ–‡æœ¬")
        return []

def create_vector_store(documents: List[Dict]):
    """åˆ›å»ºå‘é‡å­˜å‚¨"""
    try:
        logger.info(f"å¼€å§‹åˆ›å»ºå‘é‡å­˜å‚¨ï¼Œæ–‡æ¡£æ•°: {len(documents)}")
        
        embeddings = OpenAIEmbeddings()
        texts = [doc["content"] for doc in documents]
        metadatas = [doc["metadata"] for doc in documents]
        
        logger.info("æ­£åœ¨ç”Ÿæˆembeddings...")
        vector_store = FAISS.from_texts(
            texts=texts,
            embedding=embeddings,
            metadatas=metadatas
        )
        
        logger.info("å‘é‡å­˜å‚¨åˆ›å»ºæˆåŠŸ")
        return vector_store
    except Exception as e:
        logger.exception(f"åˆ›å»ºå‘é‡å­˜å‚¨å¤±è´¥: {str(e)}")
        st.error(f"åˆ›å»ºå‘é‡å­˜å‚¨å¤±è´¥: {str(e)}")
        return None

def create_advanced_prompt(question: str, context: str, question_type: str = "general") -> str:
    """åˆ›å»ºé«˜çº§å¤šé˜¶æ®µæç¤ºè¯"""
    
    # é—®é¢˜ç±»å‹åˆ¤æ–­
    if any(keyword in question.lower() for keyword in ["minimum", "æœ€ä½", "least", "min"]):
        question_type = "specific_value"
    elif any(keyword in question.lower() for keyword in ["how", "what", "explain", "ä»€ä¹ˆ", "å¦‚ä½•", "è§£é‡Š"]):
        question_type = "explanation"
    elif any(keyword in question.lower() for keyword in ["compare", "difference", "vs", "æ¯”è¾ƒ", "åŒºåˆ«"]):
        question_type = "comparison"
    
    # åŸºç¡€ç³»ç»Ÿè§’è‰²
    base_system = """You are a professional insurance product analyst with expertise in policy details, financial products, and regulatory compliance. You have deep knowledge of insurance terminology in both Chinese and English."""
    
    # é’ˆå¯¹ä¸åŒé—®é¢˜ç±»å‹çš„ä¸“ä¸šæç¤º
    type_prompts = {
        "specific_value": """
TASK: Extract and provide specific numerical or factual information.
APPROACH: 
1. Scan the context for exact values, amounts, percentages, or specific terms
2. Quote the exact information found
3. Provide the source context where you found this information
4. If multiple values exist, list them clearly
5. If no exact match is found, state clearly what information is missing
""",
        "explanation": """
TASK: Provide comprehensive explanations with clear reasoning.
APPROACH:
1. Break down complex concepts into understandable components
2. Explain the significance or implications of the information
3. Use analogies or examples if helpful
4. Structure your response logically (definition, features, benefits, etc.)
5. Cite specific evidence from the provided context
""",
        "comparison": """
TASK: Analyze and compare different options or features.
APPROACH:
1. Identify all relevant comparison points
2. Create a structured comparison highlighting differences and similarities
3. Explain the implications of each difference
4. Provide recommendations if appropriate based on the context
5. Support all comparisons with specific evidence from the context
""",
        "general": """
TASK: Provide accurate, comprehensive information based on the context.
APPROACH:
1. Directly address the specific question asked
2. Provide supporting details and context
3. Explain any technical terms used
4. Structure information clearly and logically
5. Cite specific sources from the provided context
"""
    }
    
    # è´¨é‡æ§åˆ¶æŒ‡ä»¤
    quality_control = """
QUALITY REQUIREMENTS:
- ACCURACY: Only use information explicitly stated in the provided context
- PRECISION: Quote exact figures, percentages, and terms when available
- COMPLETENESS: Address all parts of the question
- CLARITY: Use clear, professional language appropriate for insurance clients
- HONESTY: If information is not available in the context, state this clearly
- CITATIONS: Reference specific parts of the context that support your answer

LANGUAGE RULES:
- Respond in the same language as the question when possible
- For mixed-language contexts, prioritize clarity over strict language matching
- Use standard insurance terminology
- Maintain professional tone throughout
"""
    
    # è¾“å‡ºæ ¼å¼æŒ‡å¯¼
    format_guide = """
OUTPUT FORMAT:
1. Direct Answer: Start with a clear, direct response to the question
2. Supporting Details: Provide relevant background information and context
3. Specific Evidence: Quote or reference specific parts of the source material
4. Limitations: Note any limitations or missing information
5. Source Reference: Indicate which parts of the context were most relevant

If you cannot answer the question based on the provided context, clearly state:
"Based on the provided context, I cannot find sufficient information to answer [specific part of question]. The available information covers [what is available]."
"""
    
    # ç»„è£…æœ€ç»ˆæç¤º
    final_prompt = f"""{base_system}

{type_prompts[question_type]}

{quality_control}

{format_guide}

CONTEXT:
{context}

USER QUESTION: {question}

Please provide a comprehensive, accurate response following the guidelines above:"""
    
    return final_prompt

def expand_query(question: str) -> List[str]:
    """æŸ¥è¯¢æ‰©å±•å’Œé‡å†™"""
    try:
        # åŸºæœ¬æŸ¥è¯¢æ‰©å±•
        expanded_queries = [question]
        
        # å…³é”®è¯åŒä¹‰è¯æ˜ å°„
        synonyms_map = {
            "minimum premium": ["minimum premium", "min premium", "lowest premium", "æœ€ä½ä¿è´¹", "æœ€å°‘ä¿è´¹"],
            "æœ€ä½ä¿è´¹": ["minimum premium", "min premium", "lowest premium", "æœ€ä½ä¿è´¹", "æœ€å°‘ä¿è´¹"],
            "age range": ["age range", "issue age", "eligible age", "æŠ•ä¿å¹´é¾„", "å¹´é¾„èŒƒå›´"],
            "æŠ•ä¿å¹´é¾„": ["age range", "issue age", "eligible age", "æŠ•ä¿å¹´é¾„", "å¹´é¾„èŒƒå›´"],
            "death benefit": ["death benefit", "death settlement", "mortality benefit", "èº«æ•…èµ”ä»˜", "æ­»äº¡ä¿é™©é‡‘"],
            "èº«æ•…èµ”ä»˜": ["death benefit", "death settlement", "mortality benefit", "èº«æ•…èµ”ä»˜", "æ­»äº¡ä¿é™©é‡‘"],
            "cash value": ["cash value", "surrender value", "guaranteed cash value", "ç°é‡‘ä»·å€¼", "é€€ä¿ä»·å€¼"],
            "ç°é‡‘ä»·å€¼": ["cash value", "surrender value", "guaranteed cash value", "ç°é‡‘ä»·å€¼", "é€€ä¿ä»·å€¼"],
        }
        
        # æŒ‰å…³é”®è¯æ‰©å±•
        for keyword, synonyms in synonyms_map.items():
            if keyword.lower() in question.lower():
                for synonym in synonyms:
                    if synonym not in expanded_queries:
                        expanded_queries.append(question.replace(keyword, synonym))
        
        # æ·»åŠ ä¸åŒè¡¨è¾¾å½¢å¼
        if "what is" in question.lower():
            expanded_queries.append(question.replace("what is", "tell me about"))
            expanded_queries.append(question.replace("what is", "explain"))
        
        logger.info(f"æŸ¥è¯¢æ‰©å±•: {len(expanded_queries)} ä¸ªå˜ä½“")
        return expanded_queries[:5]  # é™åˆ¶æ•°é‡
    except Exception as e:
        logger.error(f"æŸ¥è¯¢æ‰©å±•å¤±è´¥: {e}")
        return [question]

def extract_keywords(text: str) -> List[str]:
    """æå–å…³é”®è¯"""
    import re
    
    # ä¿é™©ç›¸å…³å…³é”®è¯
    insurance_terms = [
        "premium", "ä¿è´¹", "policy", "ä¿å•", "coverage", "ä¿éšœ", 
        "benefit", "åˆ©ç›Š", "claim", "ç†èµ”", "deductible", "å…èµ”é¢",
        "cash value", "ç°é‡‘ä»·å€¼", "death benefit", "èº«æ•…èµ”ä»˜",
        "surrender", "é€€ä¿", "dividend", "åˆ†çº¢", "guaranteed", "ä¿è¯"
    ]
    
    # æå–æ–‡æœ¬ä¸­çš„å…³é”®è¯
    words = re.findall(r'\b\w+\b', text.lower())
    keywords = []
    
    for word in words:
        if len(word) > 3 and (word in insurance_terms or any(term in word for term in insurance_terms)):
            keywords.append(word)
    
    # æ·»åŠ æ•°å­—ç›¸å…³çš„å…³é”®è¯
    numbers = re.findall(r'\d+', text)
    keywords.extend(numbers)
    
    return list(set(keywords))[:5]  # æœ€å¤šè¿”å›5ä¸ªå…³é”®è¯

def adaptive_retrieval_strategy(vector_store, question: str, history: List = None) -> Dict:
    """è‡ªé€‚åº”æ£€ç´¢ç­–ç•¥"""
    try:
        # åˆ†æé—®é¢˜ç±»å‹
        question_type = analyze_question_type(question)
        
        # æ ¹æ®å†å²è¡¨ç°è°ƒæ•´å‚æ•°
        retrieval_params = get_adaptive_params(question_type, history)
        
        # æ‰§è¡Œæ£€ç´¢
        docs = advanced_retrieval_strategies(vector_store, question, k=retrieval_params['k'])
        
        # æ€§èƒ½ç›‘æ§
        performance_metrics = monitor_retrieval_performance(docs, question, question_type)
        
        return {
            "documents": docs,
            "question_type": question_type,
            "retrieval_params": retrieval_params,
            "performance_metrics": performance_metrics
        }
        
    except Exception as e:
        logger.error(f"è‡ªé€‚åº”æ£€ç´¢å¤±è´¥: {e}")
        return {
            "documents": vector_store.similarity_search(question, k=20),
            "question_type": "general",
            "retrieval_params": {"k": 20},
            "performance_metrics": {}
        }

def analyze_question_type(question: str) -> str:
    """åˆ†æé—®é¢˜ç±»å‹"""
    question_lower = question.lower()
    
    # å…·ä½“æ•°å€¼æŸ¥è¯¢
    if any(word in question_lower for word in ["minimum", "maximum", "æœ€ä½", "æœ€é«˜", "å¤šå°‘", "how much", "what is the"]):
        return "specific_value"
    
    # æ¯”è¾ƒç±»æŸ¥è¯¢
    if any(word in question_lower for word in ["compare", "difference", "vs", "versus", "æ¯”è¾ƒ", "åŒºåˆ«", "ä¸åŒ"]):
        return "comparison"
    
    # è§£é‡Šç±»æŸ¥è¯¢
    if any(word in question_lower for word in ["explain", "what", "why", "how", "è§£é‡Š", "ä»€ä¹ˆ", "ä¸ºä»€ä¹ˆ", "å¦‚ä½•"]):
        return "explanation"
    
    # åˆ—è¡¨ç±»æŸ¥è¯¢
    if any(word in question_lower for word in ["list", "types", "kinds", "åˆ—å‡º", "ç§ç±»", "ç±»å‹"]):
        return "listing"
    
    return "general"

def get_adaptive_params(question_type: str, history: List = None) -> Dict:
    """æ ¹æ®é—®é¢˜ç±»å‹å’Œå†å²è¡¨ç°è·å–è‡ªé€‚åº”å‚æ•°"""
    # é»˜è®¤å‚æ•°
    default_params = {
        "specific_value": {"k": 25, "mmr_lambda": 0.5, "keyword_weight": 0.3},
        "comparison": {"k": 35, "mmr_lambda": 0.8, "keyword_weight": 0.2},
        "explanation": {"k": 30, "mmr_lambda": 0.7, "keyword_weight": 0.2},
        "listing": {"k": 40, "mmr_lambda": 0.9, "keyword_weight": 0.1},
        "general": {"k": 25, "mmr_lambda": 0.7, "keyword_weight": 0.25}
    }
    
    params = default_params.get(question_type, default_params["general"])
    
    # æ ¹æ®å†å²è¡¨ç°è°ƒæ•´
    if history:
        recent_performance = [qa.get("confidence", 0.5) for qa in history[-5:] if qa.get("question_type") == question_type]
        if recent_performance:
            avg_confidence = sum(recent_performance) / len(recent_performance)
            
            # å¦‚æœè¡¨ç°ä¸ä½³ï¼Œå¢åŠ æ£€ç´¢æ•°é‡
            if avg_confidence < 0.6:
                params["k"] = min(50, int(params["k"] * 1.3))
                params["keyword_weight"] *= 1.2
            # å¦‚æœè¡¨ç°å¾ˆå¥½ï¼Œå¯ä»¥ç¨å¾®å‡å°‘æ£€ç´¢æ•°é‡ä»¥æé«˜é€Ÿåº¦
            elif avg_confidence > 0.8:
                params["k"] = max(15, int(params["k"] * 0.9))
    
    return params

def monitor_retrieval_performance(docs: List, question: str, question_type: str) -> Dict:
    """ç›‘æ§æ£€ç´¢æ€§èƒ½"""
    try:
        metrics = {
            "total_documents": len(docs),
            "question_type": question_type,
            "avg_content_length": sum(len(doc.page_content) for doc in docs) / len(docs) if docs else 0,
            "strategies_distribution": {},
            "keyword_coverage": 0.0,
            "diversity_score": 0.0
        }
        
        # ç»Ÿè®¡ç­–ç•¥åˆ†å¸ƒ
        strategies = [doc.metadata.get('strategy', 'unknown') for doc in docs]
        for strategy in set(strategies):
            metrics["strategies_distribution"][strategy] = strategies.count(strategy)
        
        # è®¡ç®—å…³é”®è¯è¦†ç›–ç‡
        question_keywords = set(extract_keywords(question))
        if question_keywords:
            doc_contents = " ".join([doc.page_content for doc in docs])
            covered_keywords = sum(1 for kw in question_keywords if kw.lower() in doc_contents.lower())
            metrics["keyword_coverage"] = covered_keywords / len(question_keywords)
        
        # è®¡ç®—å¤šæ ·æ€§åˆ†æ•°ï¼ˆåŸºäºæ–‡æ¡£é•¿åº¦å·®å¼‚ï¼‰
        if len(docs) > 1:
            content_lengths = [len(doc.page_content) for doc in docs]
            avg_length = sum(content_lengths) / len(content_lengths)
            variance = sum((length - avg_length) ** 2 for length in content_lengths) / len(content_lengths)
            metrics["diversity_score"] = min(1.0, variance / 10000)  # å½’ä¸€åŒ–
        
        return metrics
        
    except Exception as e:
        logger.error(f"æ€§èƒ½ç›‘æ§å¤±è´¥: {e}")
        return {"error": str(e)}

def advanced_retrieval_strategies(vector_store, question: str, k: int = 30) -> List:
    """é«˜çº§å¤šç­–ç•¥æ£€ç´¢èåˆ"""
    try:
        all_docs = []
        expanded_queries = expand_query(question)
        
        # ç­–ç•¥1: åŸºç¡€ç›¸ä¼¼åº¦æœç´¢
        logger.info("æ‰§è¡ŒåŸºç¡€ç›¸ä¼¼åº¦æœç´¢...")
        for query in expanded_queries:
            docs = vector_store.similarity_search(query, k=k//len(expanded_queries))
            for doc in docs:
                if not hasattr(doc, 'metadata'):
                    doc.metadata = {}
                doc.metadata['strategy'] = 'similarity'
                doc.metadata['query_used'] = query
                all_docs.append(doc)
        
        # ç­–ç•¥2: æœ€å¤§è¾¹é™…ç›¸å…³æ€§æœç´¢
        logger.info("æ‰§è¡ŒMMRæœç´¢...")
        for query in expanded_queries:
            try:
                mmr_docs = vector_store.max_marginal_relevance_search(
                    query, 
                    k=k//len(expanded_queries), 
                    fetch_k=k*2,
                    lambda_mult=0.7  # å¹³è¡¡ç›¸å…³æ€§å’Œå¤šæ ·æ€§
                )
                for doc in mmr_docs:
                    if not hasattr(doc, 'metadata'):
                        doc.metadata = {}
                    doc.metadata['strategy'] = 'mmr'
                    doc.metadata['query_used'] = query
                    all_docs.append(doc)
            except Exception as mmr_error:
                logger.warning(f"MMRæœç´¢å¤±è´¥: {mmr_error}")
        
        # ç­–ç•¥3: å¸¦åˆ†æ•°çš„ç›¸ä¼¼åº¦æœç´¢
        logger.info("æ‰§è¡Œå¸¦åˆ†æ•°çš„ç›¸ä¼¼åº¦æœç´¢...")
        try:
            scored_docs = vector_store.similarity_search_with_score(question, k=k//2)
            for doc, score in scored_docs:
                if not hasattr(doc, 'metadata'):
                    doc.metadata = {}
                doc.metadata['strategy'] = 'scored_similarity'
                doc.metadata['similarity_score'] = 1 - score  # è½¬æ¢ä¸ºç›¸ä¼¼åº¦
                doc.metadata['query_used'] = question
                all_docs.append(doc)
        except Exception as score_error:
            logger.warning(f"å¸¦åˆ†æ•°æœç´¢å¤±è´¥: {score_error}")
        
        # ç­–ç•¥4: å…³é”®è¯å¢å¼ºæœç´¢
        logger.info("æ‰§è¡Œå…³é”®è¯å¢å¼ºæœç´¢...")
        keywords = extract_keywords(question)
        for keyword in keywords:
            try:
                keyword_docs = vector_store.similarity_search(keyword, k=max(1, k//8))
                for doc in keyword_docs:
                    if not hasattr(doc, 'metadata'):
                        doc.metadata = {}
                    doc.metadata['strategy'] = 'keyword'
                    doc.metadata['keyword_used'] = keyword
                    all_docs.append(doc)
            except Exception as kw_error:
                logger.warning(f"å…³é”®è¯æœç´¢å¤±è´¥ ({keyword}): {kw_error}")
        
        # å»é‡å¤„ç†
        unique_docs = deduplicate_docs(all_docs)
        
        logger.info(f"å¤šç­–ç•¥æ£€ç´¢: åŸå§‹{len(all_docs)} -> å»é‡å{len(unique_docs)}")
        return unique_docs[:k]
        
    except Exception as e:
        logger.error(f"é«˜çº§æ£€ç´¢å¤±è´¥: {e}")
        return vector_store.similarity_search(question, k=k)

def deduplicate_docs(docs: List) -> List:
    """å»é‡æ–‡æ¡£"""
    try:
        seen_hashes = set()
        unique_docs = []
        
        for doc in docs:
            # åˆ›å»ºå†…å®¹å“ˆå¸Œ
            content_hash = hash(doc.page_content[:200])  # ä½¿ç”¨å‰200å­—ç¬¦
            
            if content_hash not in seen_hashes:
                seen_hashes.add(content_hash)
                unique_docs.append(doc)
        
        # æŒ‰ç­–ç•¥æƒé‡æ’åº
        strategy_weights = {
            'similarity': 0.4,
            'mmr': 0.3,
            'scored_similarity': 0.2,
            'keyword': 0.1
        }
        
        def get_doc_score(doc):
            strategy = doc.metadata.get('strategy', 'similarity')
            base_score = strategy_weights.get(strategy, 0.25)
            
            # å¦‚æœæœ‰ç›¸ä¼¼åº¦åˆ†æ•°ï¼Œä½¿ç”¨å®ƒ
            if 'similarity_score' in doc.metadata:
                return doc.metadata['similarity_score'] * base_score
            
            # å†…å®¹é•¿åº¦åŠ åˆ†
            content_bonus = min(0.1, len(doc.page_content) / 5000)
            return base_score + content_bonus
        
        # æ’åº
        unique_docs.sort(key=get_doc_score, reverse=True)
        
        return unique_docs
        
    except Exception as e:
        logger.error(f"å»é‡å¤±è´¥: {e}")
        return docs

def answer_question_with_confidence(question: str, vector_store) -> Dict:
    """å›ç­”é—®é¢˜å¹¶è¿”å›ç½®ä¿¡åº¦"""
    try:
        logger.info(f"å¼€å§‹å›ç­”é—®é¢˜: {question}")
        
        if not os.getenv("OPENAI_API_KEY"):
            logger.error("æœªè®¾ç½®OpenAI APIå¯†é’¥")
            return {
                "question": question,
                "answer": "è¯·å…ˆè®¾ç½®OpenAI APIå¯†é’¥",
                "sources": [],
                "confidence": 0.0,
                "timestamp": datetime.now().isoformat()
            }
        
        # å¢å¼ºçš„ç³»ç»Ÿæç¤ºï¼Œæ”¯æŒä¸­è‹±æ–‡æ··åˆ
        system_prompt = """You are an insurance product expert assistant. 
        Please answer questions based on the provided context. 
        If the context is in Chinese, you can answer in Chinese.
        If you cannot find relevant information, please say so clearly.
        Always cite the specific information from the context."""
        
        logger.info("åˆå§‹åŒ–LLM...")
        llm = ChatOpenAI(
            model_name="gpt-3.5-turbo",
            temperature=0.1,
            max_tokens=800  # å¢åŠ tokené™åˆ¶
        )
        
        logger.info("å¼€å§‹è‡ªé€‚åº”æ£€ç´¢ç­–ç•¥...")
        start_time = time.time()
        
        # ä½¿ç”¨è‡ªé€‚åº”æ£€ç´¢ç­–ç•¥
        retrieval_result = adaptive_retrieval_strategy(vector_store, question, st.session_state.qa_history)
        retrieved_docs = retrieval_result["documents"]
        question_type = retrieval_result["question_type"]
        performance_metrics = retrieval_result["performance_metrics"]
        
        # æ„å»ºä¸Šä¸‹æ–‡
        context = "\n\n".join([doc.page_content for doc in retrieved_docs])
        
        # ä½¿ç”¨é«˜çº§æç¤ºè¯å·¥ç¨‹ï¼Œæ ¹æ®é—®é¢˜ç±»å‹è°ƒæ•´
        prompt = create_advanced_prompt(question, context, question_type)
        
        # ç”Ÿæˆç­”æ¡ˆ
        response = llm.invoke(prompt)
        answer = response.content if hasattr(response, 'content') else str(response)
        
        response_time = time.time() - start_time
        
        logger.info(f"ç­”æ¡ˆç”Ÿæˆå®Œæˆï¼Œè€—æ—¶: {response_time:.2f}ç§’")
        logger.info(f"ç­”æ¡ˆå†…å®¹: {answer[:200]}...")
        
        source_documents = retrieved_docs
        logger.info(f"æ£€ç´¢åˆ° {len(source_documents)} ä¸ªç›¸å…³æ–‡æ¡£")
        
        # æ›´ç²¾ç»†çš„ç½®ä¿¡åº¦è®¡ç®—
        confidence = 0.3  # åŸºç¡€ç½®ä¿¡åº¦
        if source_documents:
            # æ ¹æ®æ–‡æ¡£æ•°é‡è°ƒæ•´ç½®ä¿¡åº¦
            doc_count = len(source_documents)
            if doc_count >= 8:
                confidence = 0.95
            elif doc_count >= 5:
                confidence = 0.85
            elif doc_count >= 3:
                confidence = 0.75
            elif doc_count >= 1:
                confidence = 0.6
        
        # å¤„ç†æ‰€æœ‰æºæ–‡æ¡£ï¼ˆæœ€å¤š15ä¸ªï¼‰
        sources = []
        for i, doc in enumerate(source_documents[:15], 1):
            # å¢åŠ æ˜¾ç¤ºçš„æ–‡æœ¬é•¿åº¦åˆ°500å­—ç¬¦
            content = doc.page_content
            # æ¸…ç†æ–‡æœ¬ï¼Œå»é™¤å¤šä½™çš„æ¢è¡Œå’Œç©ºæ ¼
            content = ' '.join(content.split())
            
            logger.debug(f"æºæ–‡æ¡£ {i}: {content[:100]}...")
            
            sources.append({
                "doc_name": doc.metadata.get("source", "Unknown"),
                "content": content[:500] + ("..." if len(content) > 500 else ""),
                "full_content": content,  # ä¿å­˜å®Œæ•´å†…å®¹
                "score": 0.95 - (i * 0.05),  # æ ¹æ®æ’åºç»™å‡ºé€’å‡çš„ç›¸å…³åº¦åˆ†æ•°
                "index": i
            })
        
        logger.info(f"ç½®ä¿¡åº¦: {confidence:.2f}, æºæ–‡æ¡£æ•°: {len(sources)}")
        
        return {
            "question": question,
            "answer": answer,
            "sources": sources,
            "confidence": confidence,
            "response_time": response_time,
            "timestamp": datetime.now().isoformat(),
            "search_strategy": "adaptive_retrieval",
            "question_type": question_type,
            "expanded_queries": expand_query(question),
            "retrieval_stats": {
                "total_docs_retrieved": len(source_documents),
                "strategies_used": ["similarity", "mmr", "scored_similarity", "keyword"],
                "keywords_extracted": extract_keywords(question)
            },
            "performance_metrics": performance_metrics
        }
    except Exception as e:
        logger.exception(f"å›ç­”é—®é¢˜æ—¶å‡ºé”™: {str(e)}")
        return {
            "question": question,
            "answer": f"é”™è¯¯: {str(e)}",
            "sources": [],
            "confidence": 0.0,
            "response_time": 0,
            "timestamp": datetime.now().isoformat()
        }

def display_confidence_badge(confidence: float):
    """æ˜¾ç¤ºç½®ä¿¡åº¦æ ‡ç­¾"""
    percentage = confidence * 100
    if confidence >= 0.7:
        badge_class = "confidence-high"
        emoji = "âœ…"
    elif confidence >= 0.3:
        badge_class = "confidence-medium"
        emoji = "âš ï¸"
    else:
        badge_class = "confidence-low"
        emoji = "âŒ"
    
    st.markdown(
        f'<span class="{badge_class}">{emoji} ç½®ä¿¡åº¦: {percentage:.1f}%</span>',
        unsafe_allow_html=True
    )

# ä¸»ç•Œé¢
st.title("ğŸ¤– ä¿é™©äº§å“æ™ºèƒ½é—®ç­”ç³»ç»Ÿ")
st.markdown("### åŸºäºRAGæŠ€æœ¯çš„ä¼ä¸šçº§PoCæ¼”ç¤º | æ”¯æŒä¸­è‹±æ–‡æ™ºèƒ½é—®ç­”")

# ä¾§è¾¹æ 
with st.sidebar:
    st.header("âš™ï¸ ç³»ç»Ÿé…ç½®")
    
    # æ˜¾ç¤ºæ—¥å¿—æŸ¥çœ‹å™¨
    with st.expander("ğŸ“‹ æŸ¥çœ‹è°ƒè¯•æ—¥å¿—", expanded=False):
        if st.button("ğŸ”„ åˆ·æ–°æ—¥å¿—"):
            try:
                with open('rag_debug.log', 'r', encoding='utf-8') as f:
                    logs = f.readlines()
                    # æ˜¾ç¤ºæœ€å50è¡Œ
                    recent_logs = logs[-50:] if len(logs) > 50 else logs
                    st.text_area(
                        "æœ€è¿‘æ—¥å¿—",
                        value=''.join(recent_logs),
                        height=300,
                        disabled=True
                    )
            except FileNotFoundError:
                st.info("æ—¥å¿—æ–‡ä»¶å°šæœªåˆ›å»º")
            except Exception as e:
                st.error(f"è¯»å–æ—¥å¿—å¤±è´¥: {e}")
        
        if st.button("ğŸ—‘ï¸ æ¸…ç©ºæ—¥å¿—"):
            try:
                open('rag_debug.log', 'w').close()
                st.success("æ—¥å¿—å·²æ¸…ç©º")
            except Exception as e:
                st.error(f"æ¸…ç©ºæ—¥å¿—å¤±è´¥: {e}")
    
    st.divider()
    
    # APIå¯†é’¥ç®¡ç†
    api_key = initialize_openai()
    
    # åˆ›å»ºä¸€ä¸ªå¯æŠ˜å çš„APIé…ç½®åŒºåŸŸ
    with st.expander("ğŸ”‘ APIå¯†é’¥é…ç½®", expanded=not bool(api_key)):
        if api_key:
            # æ˜¾ç¤ºå½“å‰APIå¯†é’¥çŠ¶æ€
            st.success("âœ… APIå¯†é’¥å·²é…ç½®")
            # æ˜¾ç¤ºéƒ¨åˆ†éšè—çš„å¯†é’¥
            masked_key = api_key[:10] + "..." + api_key[-4:] if len(api_key) > 14 else "***"
            st.info(f"å½“å‰å¯†é’¥: {masked_key}")
            
            # æä¾›é‡æ–°é…ç½®é€‰é¡¹
            if st.button("ğŸ”„ é‡æ–°é…ç½®APIå¯†é’¥", use_container_width=True):
                # æ¸…é™¤ç°æœ‰å¯†é’¥
                if 'api_key' in st.session_state:
                    del st.session_state.api_key
                os.environ.pop("OPENAI_API_KEY", None)
                st.rerun()
        
        # APIå¯†é’¥è¾“å…¥æ¡†
        new_api_key = st.text_input(
            "è¾“å…¥æ–°çš„OpenAI API Key",
            type="password",
            help="æ ¼å¼: sk-...",
            placeholder="sk-proj-..."
        )
        
        col1, col2 = st.columns(2)
        with col1:
            if st.button("âœ… ä¿å­˜å¯†é’¥", use_container_width=True, type="primary"):
                if new_api_key and new_api_key.startswith("sk-"):
                    os.environ["OPENAI_API_KEY"] = new_api_key
                    st.session_state.api_key = new_api_key
                    st.success("âœ… APIå¯†é’¥å·²æ›´æ–°")
                    time.sleep(1)
                    st.rerun()
                elif new_api_key:
                    st.error("âŒ å¯†é’¥æ ¼å¼ä¸æ­£ç¡®ï¼Œåº”ä»¥'sk-'å¼€å¤´")
        
        with col2:
            # ä».envæ–‡ä»¶é‡æ–°åŠ è½½
            if st.button("ğŸ“‚ ä».envåŠ è½½", use_container_width=True):
                try:
                    from dotenv import load_dotenv
                    load_dotenv(override=True)
                    env_key = os.getenv("OPENAI_API_KEY")
                    if env_key:
                        os.environ["OPENAI_API_KEY"] = env_key
                        st.session_state.api_key = env_key
                        st.success("âœ… å·²ä».envæ–‡ä»¶åŠ è½½å¯†é’¥")
                        time.sleep(1)
                        st.rerun()
                    else:
                        st.error("âŒ .envæ–‡ä»¶ä¸­æœªæ‰¾åˆ°OPENAI_API_KEY")
                except Exception as e:
                    st.error(f"âŒ åŠ è½½å¤±è´¥: {str(e)}")
        
        # æµ‹è¯•APIè¿æ¥
        if api_key or new_api_key:
            if st.button("ğŸ§ª æµ‹è¯•APIè¿æ¥", use_container_width=True):
                test_key = new_api_key if new_api_key else api_key
                with st.spinner("æ­£åœ¨æµ‹è¯•è¿æ¥..."):
                    try:
                        # æµ‹è¯•APIè¿æ¥
                        from openai import OpenAI
                        client = OpenAI(api_key=test_key)
                        # å‘é€ä¸€ä¸ªç®€å•çš„æµ‹è¯•è¯·æ±‚
                        response = client.chat.completions.create(
                            model="gpt-3.5-turbo",
                            messages=[{"role": "user", "content": "Hi"}],
                            max_tokens=5
                        )
                        st.success("âœ… APIè¿æ¥æˆåŠŸï¼")
                        st.info(f"æ¨¡å‹å“åº”: {response.choices[0].message.content}")
                    except Exception as e:
                        st.error(f"âŒ APIè¿æ¥å¤±è´¥: {str(e)}")
                        if "api_key" in str(e).lower():
                            st.warning("ğŸ’¡ æç¤º: è¯·æ£€æŸ¥APIå¯†é’¥æ˜¯å¦æ­£ç¡®")
                        elif "rate" in str(e).lower():
                            st.warning("ğŸ’¡ æç¤º: APIè°ƒç”¨é¢‘ç‡é™åˆ¶ï¼Œè¯·ç¨åå†è¯•")
                        else:
                            st.warning("ğŸ’¡ æç¤º: è¯·æ£€æŸ¥ç½‘ç»œè¿æ¥æˆ–APIå¯†é’¥æƒé™")
    
    st.divider()
    
    # æ–‡ä»¶ä¸Šä¼ 
    st.header("ğŸ“„ æ–‡æ¡£ç®¡ç†")
    uploaded_files = st.file_uploader(
        "é€‰æ‹©PDFæ–‡ä»¶",
        type=["pdf"],
        accept_multiple_files=True
    )
    
    if uploaded_files:
        st.info(f"å·²é€‰æ‹© {len(uploaded_files)} ä¸ªæ–‡ä»¶")
        
        # PDFè¯Šæ–­åŠŸèƒ½
        if st.checkbox("ğŸ“‹ å¯ç”¨PDFè¯Šæ–­ (æ¨è)", value=True):
            st.markdown("##### ğŸ“Š æ–‡ä»¶è¯Šæ–­ç»“æœ")
            
            all_diagnoses = []
            for file in uploaded_files:
                with st.expander(f"ğŸ“„ {file.name}"):
                    try:
                        diagnosis = diagnose_pdf(file)
                        display_pdf_diagnosis(diagnosis)
                        all_diagnoses.append(diagnosis)
                    except Exception as e:
                        st.error(f"è¯Šæ–­å¤±è´¥: {str(e)}")
                        all_diagnoses.append(None)
            
            # æ•´ä½“å»ºè®®
            processable_files = sum(1 for d in all_diagnoses if d and should_process_pdf(d))
            if processable_files < len(uploaded_files):
                st.warning(f"âš ï¸ {len(uploaded_files) - processable_files} ä¸ªæ–‡ä»¶å¯èƒ½æ— æ³•æ­£å¸¸å¤„ç†")
            
            # æ˜¾ç¤ºå¤„ç†ä¿¡æ¯
            if all_diagnoses:
                max_timeout = max([get_processing_timeout(d) for d in all_diagnoses if d], default=300)
                if max_timeout > 300:
                    st.warning(f"âš ï¸ æ£€æµ‹åˆ°å¤§æ–‡ä»¶ï¼Œå»ºè®®çš„å¤„ç†æ—¶é—´ä¸º {max_timeout//60} åˆ†é’Ÿï¼Œä½†ç³»ç»Ÿå°†ä½¿ç”¨5åˆ†é’Ÿè¶…æ—¶")
                else:
                    st.info("ğŸ’¡ æ–‡ä»¶å¤§å°é€‚ä¸­ï¼Œ5åˆ†é’Ÿå¤„ç†æ—¶é—´åº”è¯¥è¶³å¤Ÿ")
        
        # é€‰æ‹©å¤„ç†æ¨¡å¼
        col1, col2 = st.columns(2)
        with col1:
            processing_mode = st.selectbox(
                "é€‰æ‹©å¤„ç†æ¨¡å¼",
                ["å¿«é€Ÿæ¨¡å¼ (æ¨è)", "æ ‡å‡†æ¨¡å¼", "å¹¶è¡Œæ¨¡å¼"],
                help="å¿«é€Ÿæ¨¡å¼ï¼šæœ€å¿«ä½†ä¸æå–è¡¨æ ¼\næ ‡å‡†æ¨¡å¼ï¼šå®Œæ•´åŠŸèƒ½ä½†è¾ƒæ…¢\nå¹¶è¡Œæ¨¡å¼ï¼šå¤šçº¿ç¨‹å¤„ç†"
            )
        with col2:
            st.info(f"ğŸ’¡ å½“å‰æ¨¡å¼: {processing_mode}")
        
        # æ£€æŸ¥PDFå¤„ç†ä¾èµ–
        deps_ok = check_dependencies()
        if not deps_ok:
            st.warning("âš ï¸ ç¼ºå°‘PDFå¤„ç†åº“ï¼Œè¯·è¿è¡Œ: pip install pdfplumber PyPDF2")
        
        if st.button("ğŸ”„ å¤„ç†æ–‡æ¡£", use_container_width=True, type="primary", disabled=not deps_ok):
            if not api_key:
                st.error("âŒ è¯·å…ˆè®¾ç½®OpenAI APIå¯†é’¥")
            elif not deps_ok:
                st.error("âŒ ç¼ºå°‘å¿…è¦çš„PDFå¤„ç†åº“ï¼Œè¯·æ£€æŸ¥ä¾èµ–å®‰è£…")
            else:
                logger.info(f"å¼€å§‹å¤„ç† {len(uploaded_files)} ä¸ªPDFæ–‡æ¡£")
                
                # è®¾ç½®é»˜è®¤è¶…æ—¶æ—¶é—´ä¸º10åˆ†é’Ÿ
                timeout_setting = 600  # 10åˆ†é’Ÿ
                
                all_documents = []
                failed_files = []
                
                for i, file in enumerate(uploaded_files):
                    st.info(f"ğŸ“„ æ­£åœ¨å¤„ç†æ–‡ä»¶ {i+1}/{len(uploaded_files)}: {file.name}")
                    
                    try:
                        # æ ¹æ®æ¨¡å¼é€‰æ‹©å¤„ç†å™¨
                        if "å¿«é€Ÿ" in processing_mode:
                            logger.info(f"ä½¿ç”¨å¿«é€Ÿæ¨¡å¼å¤„ç† {file.name}")
                            docs = process_pdf_fast(file)
                        elif "å¹¶è¡Œ" in processing_mode:
                            logger.info(f"ä½¿ç”¨å¹¶è¡Œæ¨¡å¼å¤„ç† {file.name}")
                            docs = process_pdf_parallel(file)
                        else:
                            logger.info(f"ä½¿ç”¨æ ‡å‡†æ¨¡å¼å¤„ç† {file.name}")
                            docs = process_pdf_with_timeout(file, timeout_seconds=timeout_setting)
                        
                        if docs:
                            all_documents.extend(docs)
                            st.success(f"âœ… {file.name} å¤„ç†æˆåŠŸ: {len(docs)} ä¸ªæ–‡æœ¬å—")
                        else:
                            failed_files.append(file.name)
                            st.error(f"âŒ {file.name} å¤„ç†å¤±è´¥")
                            
                    except Exception as e:
                        failed_files.append(file.name)
                        logger.error(f"å¤„ç†æ–‡ä»¶ {file.name} æ—¶å‡ºé”™: {e}")
                        st.error(f"âŒ {file.name} å¤„ç†å‡ºé”™: {str(e)}")
                
                # å¤„ç†ç»“æœæ±‡æ€»
                if all_documents:
                    st.session_state.documents = all_documents
                    st.session_state.vector_store = create_vector_store(all_documents)
                    
                    logger.info(f"æ–‡æ¡£å¤„ç†å®Œæˆï¼Œå…± {len(all_documents)} ä¸ªæ–‡æœ¬å—")
                    
                    # æ˜¾ç¤ºå¤„ç†ç»Ÿè®¡
                    success_count = len(uploaded_files) - len(failed_files)
                    st.success(f"ğŸ‰ å¤„ç†å®Œæˆ!")
                    
                    col1, col2, col3 = st.columns(3)
                    with col1:
                        st.metric("æˆåŠŸå¤„ç†", f"{success_count}/{len(uploaded_files)}")
                    with col2:
                        st.metric("æ–‡æ¡£æ•°", len(set([d["metadata"]["source"] for d in all_documents])))
                    with col3:
                        st.metric("æ–‡æœ¬å—æ•°", len(all_documents))
                    
                    if failed_files:
                        st.warning(f"âš ï¸ ä»¥ä¸‹æ–‡ä»¶å¤„ç†å¤±è´¥: {', '.join(failed_files)}")
                    
                    st.balloons()
                else:
                    logger.error("æ²¡æœ‰æˆåŠŸå¤„ç†ä»»ä½•æ–‡æ¡£")
                    st.error("âŒ æ‰€æœ‰æ–‡æ¡£å¤„ç†éƒ½å¤±è´¥äº†")
                    
                    # æä¾›æ•…éšœæ’é™¤å»ºè®®
                    with st.expander("ğŸ› ï¸ æ•…éšœæ’é™¤å»ºè®®"):
                        st.markdown("""
                        **å¯èƒ½çš„åŸå› å’Œè§£å†³æ–¹æ¡ˆ:**
                        
                        1. **æ–‡ä»¶æŸåæˆ–åŠ å¯†**: å°è¯•ç”¨å…¶ä»–PDFé˜…è¯»å™¨æ‰“å¼€æ–‡ä»¶
                        2. **æ–‡ä»¶è¿‡å¤§**: å°è¯•æ‹†åˆ†å¤§æ–‡ä»¶æˆ–å¢åŠ è¶…æ—¶æ—¶é—´
                        3. **å¤æ‚PDFæ ¼å¼**: æŸäº›PDFå¯èƒ½åŒ…å«å¤æ‚çš„å›¾å½¢æˆ–è¡¨æ ¼
                        4. **æ‰«æç‰ˆPDF**: ç³»ç»Ÿæ— æ³•å¤„ç†å›¾ç‰‡ç‰ˆPDFï¼Œéœ€è¦OCRå·¥å…·
                        5. **ç½‘ç»œé—®é¢˜**: æ£€æŸ¥ç½‘ç»œè¿æ¥æ˜¯å¦ç¨³å®š
                        
                        **å»ºè®®æ“ä½œ:**
                        - å°è¯•å¤„ç†å•ä¸ªæ–‡ä»¶
                        - å¢åŠ å¤„ç†è¶…æ—¶æ—¶é—´
                        - æ£€æŸ¥PDFæ–‡ä»¶æ˜¯å¦å¯ä»¥æ­£å¸¸æ‰“å¼€
                        - å°è¯•å°†PDFè½¬æ¢ä¸ºæ–‡æœ¬æ ¼å¼
                        """)

# ä¸»è¦å†…å®¹åŒºåŸŸ
if st.session_state.vector_store:
    # æ˜¾ç¤ºç³»ç»ŸçŠ¶æ€
    status_cols = st.columns(5)
    with status_cols[0]:
        st.metric("æ–‡æ¡£æ•°", len(set([d["metadata"]["source"] for d in st.session_state.documents])))
    with status_cols[1]:
        st.metric("æ–‡æœ¬å—", len(st.session_state.documents))
    with status_cols[2]:
        st.metric("å†å²é—®ç­”", len(st.session_state.qa_history))
    with status_cols[3]:
        avg_confidence = sum([qa["confidence"] for qa in st.session_state.qa_history[-10:]]) / min(10, len(st.session_state.qa_history)) if st.session_state.qa_history else 0
        st.metric("å¹³å‡ç½®ä¿¡åº¦", f"{avg_confidence:.1%}")
    with status_cols[4]:
        # æ˜¾ç¤ºæœ€å¸¸è§çš„é—®é¢˜ç±»å‹
        if st.session_state.qa_history:
            question_types = [qa.get("question_type", "general") for qa in st.session_state.qa_history[-10:]]
            most_common_type = max(set(question_types), key=question_types.count) if question_types else "general"
            st.metric("ä¸»è¦é—®é¢˜ç±»å‹", most_common_type.replace("_", " ").title())
        else:
            st.metric("ç³»ç»ŸçŠ¶æ€", "âœ… å°±ç»ª")
    
    # è‡ªå®šä¹‰å¯¼èˆªæ 
    st.markdown("---")
    nav_cols = st.columns(4)
    
    pages = ["ğŸ’¬ æ™ºèƒ½é—®ç­”", "ğŸ“‹ é—®é¢˜åˆ†ç±»", "ğŸ“Š æ‰¹é‡é—®ç­”", "ğŸ“ˆ æ€§èƒ½ç›‘æ§"]
    
    for i, page in enumerate(pages):
        with nav_cols[i]:
            if st.button(page, key=f"nav_{i}", use_container_width=True,
                        type="primary" if st.session_state.current_page == page.split()[1] else "secondary"):
                st.session_state.current_page = page.split()[1]
                st.rerun()
    
    st.markdown("---")
    
    # æ ¹æ®å½“å‰é¡µé¢æ˜¾ç¤ºå†…å®¹
    if st.session_state.current_page == "æ™ºèƒ½é—®ç­”":
        # å¦‚æœæœ‰å¾…å¤„ç†çš„é—®é¢˜
        if st.session_state.auto_submit and st.session_state.selected_question:
            st.info(f"ğŸ’¡ æ­£åœ¨å›ç­”é—®é¢˜ï¼š{st.session_state.selected_question}")
            
            with st.spinner("ğŸ¤” æ­£åœ¨åˆ†æ..."):
                result = answer_question_with_confidence(
                    st.session_state.selected_question, 
                    st.session_state.vector_store
                )
                st.session_state.qa_history.insert(0, result)
                st.session_state.last_answer = result
                st.session_state.auto_submit = False
            
            # æ˜¾ç¤ºç­”æ¡ˆ
            col1, col2 = st.columns([3, 1])
            with col1:
                st.markdown("### ğŸ“ AIå›ç­”")
            with col2:
                display_confidence_badge(result["confidence"])
            
            st.markdown(f"""
            <div class="answer-card">
                {result["answer"]}
            </div>
            """, unsafe_allow_html=True)
            
            # æ˜¾ç¤ºæ‰€æœ‰ä¿¡æ¯æ¥æºï¼ˆæœ€å¤š10ä¸ªï¼‰
            if result["sources"]:
                st.markdown("### ğŸ“š ä¿¡æ¯æ¥æº")
                st.info(f"æ‰¾åˆ° {len(result['sources'])} ä¸ªç›¸å…³æ–‡æ¡£ç‰‡æ®µ")
                
                for source in result["sources"]:
                    score = source.get('score', 0)
                    if score >= 0.8:
                        score_color = "ğŸŸ¢"
                    elif score >= 0.6:
                        score_color = "ğŸŸ¡"
                    else:
                        score_color = "ğŸ”´"
                    
                    with st.expander(
                        f"{score_color} æ¥æº {source.get('index', '')} | {source['doc_name']} | ç›¸å…³åº¦: {score:.2%} | å—: {source.get('chunk_index', 'N/A')}",
                        expanded=(source.get('index', 0) <= 3)
                    ):
                        st.markdown("**æ–‡æ¡£å†…å®¹ç‰‡æ®µï¼š**")
                        st.text_area(
                            "",
                            value=source.get('full_content', source['content']),
                            height=150,
                            disabled=True,
                            key=f"auto_source_{source.get('index', '')}_{id(source)}"
                        )
                        
                        col1, col2 = st.columns(2)
                        with col1:
                            st.caption(f"ğŸ“„ æ–‡æ¡£: {source['doc_name']}")
                        with col2:
                            st.caption(f"ğŸ“Š ç›¸å…³åº¦å¾—åˆ†: {score:.2%}")
            
            st.divider()
        
        # çƒ­é—¨é—®é¢˜
        st.markdown("#### ğŸ”¥ çƒ­é—¨é—®é¢˜")
        cols = st.columns(len(HOT_QUESTIONS))
        for i, (label, question) in enumerate(HOT_QUESTIONS):
            with cols[i]:
                if st.button(label, key=f"hot_{i}", use_container_width=True):
                    st.session_state.selected_question = question
                    st.session_state.auto_submit = True
                    st.rerun()
        
        st.divider()
        
        # æ˜¾ç¤ºæœ€è¿‘çš„å›ç­”ï¼ˆå¦‚æœæœ‰ï¼‰
        if st.session_state.last_answer and not st.session_state.auto_submit:
            st.markdown("### ğŸ“Œ æœ€è¿‘å›ç­”")
            col1, col2 = st.columns([3, 1])
            with col1:
                st.info(f"é—®é¢˜: {st.session_state.last_answer['question']}")
            with col2:
                display_confidence_badge(st.session_state.last_answer["confidence"])
            
            st.markdown(f"""
            <div class="answer-card">
                {st.session_state.last_answer["answer"]}
            </div>
            """, unsafe_allow_html=True)
            
            st.divider()
        
        # é—®é¢˜è¾“å…¥
        col1, col2 = st.columns([4, 1])
        with col1:
            question = st.text_input(
                "è¾“å…¥æ‚¨çš„é—®é¢˜",
                value="" if st.session_state.auto_submit else st.session_state.selected_question,
                placeholder="ä¾‹å¦‚: What is the minimum premium?",
                key="question_input"
            )
        with col2:
            submit_button = st.button("ğŸ” æé—®", type="primary", use_container_width=True)
        
        # å¤„ç†æé—®
        if submit_button:
            if question and question.strip():
                st.info(f"ğŸ“ æ­£åœ¨å¤„ç†é—®é¢˜: {question}")
                
                try:
                    with st.spinner("ğŸ¤” æ­£åœ¨æ€è€ƒä¸­..."):
                        result = answer_question_with_confidence(question, st.session_state.vector_store)
                        st.session_state.qa_history.insert(0, result)
                        st.session_state.last_answer = result
                    
                    # æ˜¾ç¤ºç­”æ¡ˆ
                    st.success("âœ… å›ç­”æˆåŠŸ")
                    st.markdown("---")
                    
                    col1, col2 = st.columns([3, 1])
                    with col1:
                        st.markdown("### ğŸ“ AIå›ç­”")
                    with col2:
                        display_confidence_badge(result["confidence"])
                    
                    st.markdown(f"""
                    <div class="answer-card">
                        {result["answer"]}
                    </div>
                    """, unsafe_allow_html=True)
                    
                    # æ˜¾ç¤ºå“åº”æ—¶é—´
                    if "response_time" in result:
                        st.caption(f"â±ï¸ å“åº”æ—¶é—´: {result['response_time']:.2f}ç§’")
                    
                    # æ˜¾ç¤ºæ‰€æœ‰ä¿¡æ¯æ¥æºï¼ˆæœ€å¤š10ä¸ªï¼‰
                    if result["sources"]:
                        st.markdown("### ğŸ“š ä¿¡æ¯æ¥æº")
                        st.info(f"æ‰¾åˆ° {len(result['sources'])} ä¸ªç›¸å…³æ–‡æ¡£ç‰‡æ®µ")
                        
                        # æ˜¾ç¤ºæ¯ä¸ªæ¥æº
                        for source in result["sources"]:
                            # ä½¿ç”¨ä¸åŒçš„é¢œè‰²æ ‡è®°ç›¸å…³åº¦
                            score = source.get('score', 0)
                            if score >= 0.8:
                                score_color = "ğŸŸ¢"  # é«˜ç›¸å…³åº¦
                            elif score >= 0.6:
                                score_color = "ğŸŸ¡"  # ä¸­ç›¸å…³åº¦
                            else:
                                score_color = "ğŸ”´"  # ä½ç›¸å…³åº¦
                            
                            # åˆ›å»ºå¯å±•å¼€çš„åŒºåŸŸæ˜¾ç¤ºæ¯ä¸ªæ¥æº
                            with st.expander(
                                f"{score_color} æ¥æº {source.get('index', '')} | {source['doc_name']} | ç›¸å…³åº¦: {score:.2%} | å—: {source.get('chunk_index', 'N/A')}",
                                expanded=(source.get('index', 0) <= 3)  # é»˜è®¤å±•å¼€å‰3ä¸ª
                            ):
                                # æ˜¾ç¤ºå†…å®¹
                                st.markdown("**æ–‡æ¡£å†…å®¹ç‰‡æ®µï¼š**")
                                st.text_area(
                                    "",
                                    value=source.get('full_content', source['content']),
                                    height=150,
                                    disabled=True,
                                    key=f"source_content_{source.get('index', '')}_{id(source)}"
                                )
                                
                                # æ˜¾ç¤ºå…ƒä¿¡æ¯
                                col1, col2 = st.columns(2)
                                with col1:
                                    st.caption(f"ğŸ“„ æ–‡æ¡£: {source['doc_name']}")
                                with col2:
                                    st.caption(f"ğŸ“Š ç›¸å…³åº¦å¾—åˆ†: {score:.2%}")
                
                except Exception as e:
                    st.error(f"âŒ å¤„ç†é—®é¢˜æ—¶å‡ºé”™: {str(e)}")
                    st.exception(e)
            else:
                st.warning("âš ï¸ è¯·è¾“å…¥é—®é¢˜")
    
    elif st.session_state.current_page == "é—®é¢˜åˆ†ç±»":
        st.markdown("### ğŸ“‹ å¯å›ç­”é—®é¢˜åˆ—è¡¨")
        st.success("ğŸ’¡ ç‚¹å‡»é—®é¢˜å°†è‡ªåŠ¨è·³è½¬åˆ°æ™ºèƒ½é—®ç­”é¡µé¢å¹¶è·å–ç­”æ¡ˆ")
        
        for category_name, category_data in QUESTION_CATEGORIES.items():
            st.markdown(f"""
            <div class="category-header">
                {category_name} {category_data['completion']}
            </div>
            """, unsafe_allow_html=True)
            
            for cn_name, en_question, is_answerable in category_data["questions"]:
                col1, col2 = st.columns([4, 1])
                with col1:
                    if is_answerable:
                        if st.button(f"âœ… {cn_name}", key=f"cat_{en_question}", 
                                   use_container_width=True):
                            # è®¾ç½®é—®é¢˜å¹¶åˆ‡æ¢é¡µé¢
                            st.session_state.selected_question = en_question
                            st.session_state.auto_submit = True
                            st.session_state.current_page = "æ™ºèƒ½é—®ç­”"
                            st.rerun()
                    else:
                        st.button(f"âŒ {cn_name}", key=f"cat_{en_question}", 
                                use_container_width=True, disabled=True)
                with col2:
                    if is_answerable:
                        st.success("å¯å›ç­”")
                    else:
                        st.error("ä¸å¯ç”¨")
    
    elif st.session_state.current_page == "æ‰¹é‡é—®ç­”":
        st.markdown("### ğŸš€ æ‰¹é‡å›ç­”é¢„è®¾é—®é¢˜")
        
        col1, col2 = st.columns(2)
        
        with col1:
            if st.button("å¼€å§‹æ‰¹é‡é—®ç­”", type="primary", use_container_width=True):
                all_questions = []
                for category_data in QUESTION_CATEGORIES.values():
                    for cn_name, en_question, is_answerable in category_data["questions"]:
                        if is_answerable:
                            all_questions.append((cn_name, en_question))
                
                progress = st.progress(0)
                batch_results = []
                
                for i, (cn_name, question) in enumerate(all_questions):
                    with st.spinner(f"å¤„ç†: {cn_name}"):
                        result = answer_question_with_confidence(question, st.session_state.vector_store)
                        st.session_state.qa_history.insert(0, result)
                        batch_results.append((cn_name, result))
                        progress.progress((i + 1) / len(all_questions))
                
                # æ˜¾ç¤ºæ‰¹é‡ç»“æœç»Ÿè®¡
                st.success(f"âœ… å®Œæˆ {len(all_questions)} ä¸ªé—®é¢˜")
                
                # å¬å›ç‡åˆ†æ
                high_conf = sum(1 for _, r in batch_results if r["confidence"] >= 0.7)
                med_conf = sum(1 for _, r in batch_results if 0.4 <= r["confidence"] < 0.7)
                low_conf = sum(1 for _, r in batch_results if r["confidence"] < 0.4)
                
                st.markdown("#### ğŸ“Š å¬å›è´¨é‡åˆ†æ")
                col1, col2, col3 = st.columns(3)
                with col1:
                    st.metric("é«˜ç½®ä¿¡åº¦ (â‰¥70%)", high_conf, f"{high_conf/len(all_questions)*100:.1f}%")
                with col2:
                    st.metric("ä¸­ç½®ä¿¡åº¦ (40-70%)", med_conf, f"{med_conf/len(all_questions)*100:.1f}%")
                with col3:
                    st.metric("ä½ç½®ä¿¡åº¦ (<40%)", low_conf, f"{low_conf/len(all_questions)*100:.1f}%")
        
        with col2:
            if st.button("ğŸ“ˆ å¬å›ç‡æµ‹è¯•", type="secondary", use_container_width=True):
                st.markdown("#### ğŸ” å¬å›ç‡æµ‹è¯•ç»“æœ")
                
                # æµ‹è¯•æŸ¥è¯¢é›†åˆ
                test_queries = [
                    ("æœ€ä½ä¿è´¹æµ‹è¯•", ["minimum premium", "æœ€ä½ä¿è´¹", "min premium"]),
                    ("æŠ•ä¿å¹´é¾„æµ‹è¯•", ["age range", "æŠ•ä¿å¹´é¾„", "issue age"]),
                    ("ç°é‡‘ä»·å€¼æµ‹è¯•", ["cash value", "ç°é‡‘ä»·å€¼", "surrender value"]),
                ]
                
                for test_name, queries in test_queries:
                    st.markdown(f"**{test_name}**")
                    
                    all_docs = []
                    for query in queries:
                        docs = st.session_state.vector_store.similarity_search(query, k=5)
                        all_docs.extend(docs)
                    
                    # å»é‡
                    unique_docs = []
                    seen = set()
                    for doc in all_docs:
                        doc_id = hash(doc.page_content[:50])
                        if doc_id not in seen:
                            seen.add(doc_id)
                            unique_docs.append(doc)
                    
                    col1, col2 = st.columns(2)
                    with col1:
                        st.info(f"æŸ¥è¯¢å˜ä½“: {len(queries)} ä¸ª")
                    with col2:
                        st.success(f"æ£€ç´¢æ–‡æ¡£: {len(unique_docs)} ä¸ª")
                    
                    # æ˜¾ç¤ºéƒ¨åˆ†ç»“æœ
                    for i, doc in enumerate(unique_docs[:3]):
                        with st.expander(f"æ–‡æ¡£ç‰‡æ®µ {i+1}"):
                            st.text(doc.page_content[:300] + "...")
                    
                    st.divider()
    
    elif st.session_state.current_page == "æ€§èƒ½ç›‘æ§":
        st.markdown("### ğŸ“ˆ ç³»ç»Ÿæ€§èƒ½ç›‘æ§")
        
        if st.session_state.qa_history:
            # æ•´ä½“æ€§èƒ½ç»Ÿè®¡
            col1, col2, col3, col4 = st.columns(4)
            
            with col1:
                total_queries = len(st.session_state.qa_history)
                st.metric("æ€»æŸ¥è¯¢æ•°", total_queries)
            
            with col2:
                avg_response_time = sum([qa.get("response_time", 0) for qa in st.session_state.qa_history]) / total_queries
                st.metric("å¹³å‡å“åº”æ—¶é—´", f"{avg_response_time:.2f}ç§’")
            
            with col3:
                high_confidence_queries = sum(1 for qa in st.session_state.qa_history if qa.get("confidence", 0) >= 0.7)
                success_rate = high_confidence_queries / total_queries
                st.metric("é«˜ç½®ä¿¡åº¦ç‡", f"{success_rate:.1%}")
            
            with col4:
                question_types = [qa.get("question_type", "general") for qa in st.session_state.qa_history]
                unique_types = len(set(question_types))
                st.metric("é—®é¢˜ç±»å‹æ•°", unique_types)
            
            st.divider()
            
            # é—®é¢˜ç±»å‹åˆ†æ
            st.markdown("#### ğŸ“Š é—®é¢˜ç±»å‹åˆ†æ")
            col1, col2 = st.columns(2)
            
            with col1:
                # é—®é¢˜ç±»å‹åˆ†å¸ƒ
                from collections import Counter
                type_counts = Counter(question_types)
                
                st.markdown("**é—®é¢˜ç±»å‹åˆ†å¸ƒï¼š**")
                for qtype, count in type_counts.most_common():
                    percentage = count / total_queries * 100
                    st.text(f"â€¢ {qtype.replace('_', ' ').title()}: {count} ({percentage:.1f}%)")
            
            with col2:
                # å„ç±»å‹å¹³å‡ç½®ä¿¡åº¦
                st.markdown("**å„ç±»å‹å¹³å‡ç½®ä¿¡åº¦ï¼š**")
                type_confidence = {}
                for qtype in set(question_types):
                    confidences = [qa["confidence"] for qa in st.session_state.qa_history if qa.get("question_type") == qtype]
                    if confidences:
                        avg_conf = sum(confidences) / len(confidences)
                        type_confidence[qtype] = avg_conf
                        st.text(f"â€¢ {qtype.replace('_', ' ').title()}: {avg_conf:.1%}")
            
            st.divider()
            
            # æ£€ç´¢ç­–ç•¥æ•ˆæœåˆ†æ
            st.markdown("#### ğŸ” æ£€ç´¢ç­–ç•¥æ•ˆæœ")
            
            retrieval_stats = []
            for qa in st.session_state.qa_history:
                if "performance_metrics" in qa and qa["performance_metrics"]:
                    metrics = qa["performance_metrics"]
                    retrieval_stats.append({
                        "question_type": qa.get("question_type", "general"),
                        "confidence": qa.get("confidence", 0),
                        "keyword_coverage": metrics.get("keyword_coverage", 0),
                        "diversity_score": metrics.get("diversity_score", 0),
                        "total_documents": metrics.get("total_documents", 0)
                    })
            
            if retrieval_stats:
                col1, col2, col3 = st.columns(3)
                
                with col1:
                    avg_coverage = sum([s["keyword_coverage"] for s in retrieval_stats]) / len(retrieval_stats)
                    st.metric("å¹³å‡å…³é”®è¯è¦†ç›–ç‡", f"{avg_coverage:.1%}")
                
                with col2:
                    avg_diversity = sum([s["diversity_score"] for s in retrieval_stats]) / len(retrieval_stats)
                    st.metric("å¹³å‡å†…å®¹å¤šæ ·æ€§", f"{avg_diversity:.2f}")
                
                with col3:
                    avg_docs = sum([s["total_documents"] for s in retrieval_stats]) / len(retrieval_stats)
                    st.metric("å¹³å‡æ£€ç´¢æ–‡æ¡£æ•°", f"{avg_docs:.1f}")
            
            st.divider()
            
            # æœ€è¿‘æŸ¥è¯¢è¯¦æƒ…
            st.markdown("#### ğŸ“‹ æœ€è¿‘æŸ¥è¯¢è¯¦æƒ…")
            
            for i, qa in enumerate(st.session_state.qa_history[:5], 1):
                with st.expander(f"æŸ¥è¯¢ {i}: {qa['question'][:50]}..."):
                    col1, col2 = st.columns(2)
                    
                    with col1:
                        st.text(f"é—®é¢˜ç±»å‹: {qa.get('question_type', 'general')}")
                        st.text(f"ç½®ä¿¡åº¦: {qa.get('confidence', 0):.1%}")
                        st.text(f"å“åº”æ—¶é—´: {qa.get('response_time', 0):.2f}ç§’")
                    
                    with col2:
                        if "performance_metrics" in qa:
                            metrics = qa["performance_metrics"]
                            st.text(f"å…³é”®è¯è¦†ç›–: {metrics.get('keyword_coverage', 0):.1%}")
                            st.text(f"æ£€ç´¢æ–‡æ¡£æ•°: {metrics.get('total_documents', 0)}")
                            if "strategies_distribution" in metrics:
                                strategies = ", ".join([f"{k}:{v}" for k, v in metrics["strategies_distribution"].items()])
                                st.text(f"ç­–ç•¥åˆ†å¸ƒ: {strategies}")
        else:
            st.info("æš‚æ— æ€§èƒ½æ•°æ®")
    
    elif st.session_state.current_page == "å†å²è®°å½•":
        st.markdown("### ğŸ“œ é—®ç­”å†å²")
        
        if st.session_state.qa_history:
            for item in st.session_state.qa_history[:10]:
                with st.expander(f"â“ {item['question'][:50]}..."):
                    st.write(f"**ç­”æ¡ˆ:** {item['answer']}")
                    if 'confidence' in item:
                        display_confidence_badge(item['confidence'])
                    if 'question_type' in item:
                        st.caption(f"é—®é¢˜ç±»å‹: {item['question_type']} | æ—¶é—´: {item['timestamp']}")
                    else:
                        st.caption(f"æ—¶é—´: {item['timestamp']}")
        else:
            st.info("æš‚æ— å†å²è®°å½•")

else:
    st.info("ğŸ‘† è¯·å…ˆåœ¨ä¾§è¾¹æ ä¸Šä¼ PDFæ–‡æ¡£å¼€å§‹ä½¿ç”¨")
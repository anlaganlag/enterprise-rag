"""
ä¿é™©äº§å“RAGç³»ç»Ÿ - Streamlitå…è´¹éƒ¨ç½²ç‰ˆæœ¬
ä¼˜åŒ–äº†å†…å­˜ä½¿ç”¨ï¼Œé€‚é…Streamlit Cloudé™åˆ¶
"""
import streamlit as st
import os
from typing import List, Dict
import json
import hashlib
from datetime import datetime
import pandas as pd

# æ ¸å¿ƒåº“
import openai
from langchain.text_splitter import RecursiveCharacterTextSplitter
from langchain_openai import OpenAIEmbeddings, ChatOpenAI
from langchain_community.vectorstores import FAISS
from langchain.chains import RetrievalQA
import pypdf2
import pdfplumber

# é¡µé¢é…ç½®
st.set_page_config(
    page_title="ä¿é™©äº§å“æ™ºèƒ½é—®ç­”ç³»ç»Ÿ",
    page_icon="ğŸ¥",
    layout="wide",
    initial_sidebar_state="expanded"
)

# æ ·å¼å®šåˆ¶
st.markdown("""
<style>
    .main { padding: 0rem 1rem; }
    .stAlert { padding: 1rem; margin: 1rem 0; }
    h1 { color: #1e3a8a; }
    .question-card {
        background: #f8fafc;
        border-radius: 8px;
        padding: 1rem;
        margin: 0.5rem 0;
        border-left: 4px solid #3b82f6;
    }
    .answer-card {
        background: #f0f9ff;
        border-radius: 8px;
        padding: 1rem;
        margin: 0.5rem 0;
    }
</style>
""", unsafe_allow_html=True)

# åˆå§‹åŒ–session state
if 'vector_store' not in st.session_state:
    st.session_state.vector_store = None
if 'qa_history' not in st.session_state:
    st.session_state.qa_history = []
if 'documents' not in st.session_state:
    st.session_state.documents = []

# é¢„å®šä¹‰é—®é¢˜åˆ—è¡¨
PRESET_QUESTIONS = [
    "What is the minimum premium?",
    "What is the policy currency?",
    "What is the minimum issue age?",
    "What is the maximum issue age?",
    "What is the benefit term?",
    "What are the premium payment terms available?",
    "What premium payment modes are available?",
    "What is the minimum modal premium?",
    "What is the minimum prepayment amount?",
    "What is the prepayment interest rate?",
    "What are the non-guaranteed benefits or returns?",
    "What are the guaranteed benefits or returns?",
    "What is the surrender value?",
    "What are the fees and charges?",
    "What is the free-look period?",
    "What is the premium holiday option?",
    "What are the exclusions?",
    "What are the riders available?",
    "What is the automatic premium loan?",
    "What is the grace period for premium payment?",
    "What are the paid-up options?",
    "What is the policy loan feature?",
    "What is the maximum policy loan amount?",
    "What is the policy loan interest rate?",
    "What are the partial withdrawal options?",
    "What is the minimum partial withdrawal amount?",
    "What is the maximum partial withdrawal amount?",
    "What are the settlement options?",
    "What are the tax benefits?",
    "What is the bonus structure?",
    "What are the death benefit options?",
    "What is the maturity benefit?",
    "What is the accidental death benefit?",
    "What are the total death benefit components?"
]

@st.cache_resource
def initialize_openai():
    """åˆå§‹åŒ–OpenAIå®¢æˆ·ç«¯"""
    api_key = st.secrets.get("OPENAI_API_KEY") or os.getenv("OPENAI_API_KEY")
    if not api_key:
        return None
    openai.api_key = api_key
    return api_key

@st.cache_data
def process_pdf(uploaded_file) -> List[Dict]:
    """å¤„ç†PDFæ–‡ä»¶"""
    chunks = []
    try:
        # ä½¿ç”¨pdfplumberæå–æ–‡æœ¬
        with pdfplumber.open(uploaded_file) as pdf:
            text = ""
            for page_num, page in enumerate(pdf.pages, 1):
                page_text = page.extract_text() or ""
                text += f"\n[Page {page_num}]\n{page_text}\n"
                
                # æå–è¡¨æ ¼
                tables = page.extract_tables()
                for table in tables:
                    if table:
                        df = pd.DataFrame(table[1:], columns=table[0])
                        text += f"\n[Table on Page {page_num}]\n{df.to_string()}\n"
        
        # æ–‡æœ¬åˆ†å—
        text_splitter = RecursiveCharacterTextSplitter(
            chunk_size=800,
            chunk_overlap=200,
            separators=["\n\n", "\n", ".", ",", " ", ""]
        )
        
        chunks = text_splitter.split_text(text)
        return [{"content": chunk, "metadata": {"source": uploaded_file.name}} for chunk in chunks]
    
    except Exception as e:
        st.error(f"PDFå¤„ç†é”™è¯¯: {str(e)}")
        return []

def create_vector_store(documents: List[Dict]):
    """åˆ›å»ºå‘é‡å­˜å‚¨"""
    try:
        embeddings = OpenAIEmbeddings()
        texts = [doc["content"] for doc in documents]
        metadatas = [doc["metadata"] for doc in documents]
        
        vector_store = FAISS.from_texts(
            texts=texts,
            embedding=embeddings,
            metadatas=metadatas
        )
        return vector_store
    except Exception as e:
        st.error(f"åˆ›å»ºå‘é‡å­˜å‚¨å¤±è´¥: {str(e)}")
        return None

def answer_question(question: str, vector_store) -> Dict:
    """å›ç­”é—®é¢˜"""
    try:
        llm = ChatOpenAI(
            model_name="gpt-3.5-turbo",
            temperature=0.1,
            max_tokens=500
        )
        
        qa_chain = RetrievalQA.from_chain_type(
            llm=llm,
            chain_type="stuff",
            retriever=vector_store.as_retriever(
                search_kwargs={"k": 5}
            ),
            return_source_documents=True
        )
        
        result = qa_chain({"query": question})
        
        return {
            "question": question,
            "answer": result["result"],
            "sources": [doc.metadata.get("source", "Unknown") for doc in result.get("source_documents", [])][:3],
            "timestamp": datetime.now().isoformat()
        }
    except Exception as e:
        return {
            "question": question,
            "answer": f"é”™è¯¯: {str(e)}",
            "sources": [],
            "timestamp": datetime.now().isoformat()
        }

# ä¸»ç•Œé¢
st.title("ğŸ¥ ä¿é™©äº§å“æ™ºèƒ½é—®ç­”ç³»ç»Ÿ")
st.markdown("### åŸºäºRAGæŠ€æœ¯çš„ä¿é™©æ–‡æ¡£æ™ºèƒ½åˆ†æ")

# ä¾§è¾¹æ 
with st.sidebar:
    st.header("âš™ï¸ é…ç½®")
    
    # APIå¯†é’¥è¾“å…¥
    if not st.secrets.get("OPENAI_API_KEY"):
        api_key_input = st.text_input(
            "OpenAI API Key",
            type="password",
            help="è¯·è¾“å…¥æ‚¨çš„OpenAI APIå¯†é’¥"
        )
        if api_key_input:
            os.environ["OPENAI_API_KEY"] = api_key_input
            st.success("APIå¯†é’¥å·²è®¾ç½®")
    
    st.divider()
    
    # æ–‡ä»¶ä¸Šä¼ 
    st.header("ğŸ“„ æ–‡æ¡£ä¸Šä¼ ")
    uploaded_files = st.file_uploader(
        "é€‰æ‹©PDFæ–‡ä»¶",
        type=["pdf"],
        accept_multiple_files=True,
        help="æ”¯æŒä¸Šä¼ å¤šä¸ªPDFæ–‡ä»¶"
    )
    
    if uploaded_files:
        if st.button("ğŸ”„ å¤„ç†æ–‡æ¡£", use_container_width=True):
            with st.spinner("æ­£åœ¨å¤„ç†PDFæ–‡æ¡£..."):
                all_documents = []
                progress = st.progress(0)
                
                for i, file in enumerate(uploaded_files):
                    docs = process_pdf(file)
                    all_documents.extend(docs)
                    progress.progress((i + 1) / len(uploaded_files))
                
                if all_documents:
                    st.session_state.documents = all_documents
                    st.session_state.vector_store = create_vector_store(all_documents)
                    st.success(f"âœ… æˆåŠŸå¤„ç† {len(uploaded_files)} ä¸ªæ–‡ä»¶ï¼Œå…± {len(all_documents)} ä¸ªæ–‡æœ¬å—")
    
    # æ˜¾ç¤ºçŠ¶æ€
    st.divider()
    st.header("ğŸ“Š ç³»ç»ŸçŠ¶æ€")
    if st.session_state.vector_store:
        st.success("âœ… å‘é‡åº“å·²å°±ç»ª")
        st.info(f"æ–‡æ¡£æ•°: {len(st.session_state.documents)}")
    else:
        st.warning("âš ï¸ è¯·å…ˆä¸Šä¼ å¹¶å¤„ç†æ–‡æ¡£")
    
    # æ¸…é™¤å†å²
    if st.button("ğŸ—‘ï¸ æ¸…é™¤å†å²", use_container_width=True):
        st.session_state.qa_history = []
        st.rerun()

# ä¸»è¦å†…å®¹åŒºåŸŸ
if st.session_state.vector_store:
    # åˆ›å»ºä¸¤åˆ—å¸ƒå±€
    col1, col2 = st.columns([2, 1])
    
    with col1:
        st.header("ğŸ’¬ é—®ç­”ç•Œé¢")
        
        # é—®é¢˜è¾“å…¥æ–¹å¼é€‰æ‹©
        input_mode = st.radio(
            "é€‰æ‹©è¾“å…¥æ–¹å¼",
            ["è‡ªå®šä¹‰é—®é¢˜", "é¢„è®¾é—®é¢˜", "æ‰¹é‡é—®ç­”"],
            horizontal=True
        )
        
        if input_mode == "è‡ªå®šä¹‰é—®é¢˜":
            question = st.text_input(
                "è¾“å…¥æ‚¨çš„é—®é¢˜",
                placeholder="ä¾‹å¦‚: What is the minimum premium?"
            )
            
            if st.button("ğŸ” è·å–ç­”æ¡ˆ", use_container_width=True):
                if question:
                    with st.spinner("æ­£åœ¨åˆ†æ..."):
                        result = answer_question(question, st.session_state.vector_store)
                        st.session_state.qa_history.insert(0, result)
                        st.rerun()
        
        elif input_mode == "é¢„è®¾é—®é¢˜":
            selected_question = st.selectbox(
                "é€‰æ‹©ä¸€ä¸ªé¢„è®¾é—®é¢˜",
                PRESET_QUESTIONS
            )
            
            if st.button("ğŸ” è·å–ç­”æ¡ˆ", use_container_width=True):
                with st.spinner("æ­£åœ¨åˆ†æ..."):
                    result = answer_question(selected_question, st.session_state.vector_store)
                    st.session_state.qa_history.insert(0, result)
                    st.rerun()
        
        else:  # æ‰¹é‡é—®ç­”
            if st.button("ğŸš€ å›ç­”æ‰€æœ‰é¢„è®¾é—®é¢˜", use_container_width=True):
                progress = st.progress(0)
                status = st.empty()
                
                for i, question in enumerate(PRESET_QUESTIONS):
                    status.text(f"æ­£åœ¨å¤„ç†: {question[:50]}...")
                    result = answer_question(question, st.session_state.vector_store)
                    st.session_state.qa_history.insert(0, result)
                    progress.progress((i + 1) / len(PRESET_QUESTIONS))
                
                st.success(f"âœ… å·²å®Œæˆ {len(PRESET_QUESTIONS)} ä¸ªé—®é¢˜")
                st.rerun()
        
        # æ˜¾ç¤ºå†å²è®°å½•
        st.divider()
        st.header("ğŸ“ é—®ç­”å†å²")
        
        for item in st.session_state.qa_history[:10]:  # æ˜¾ç¤ºæœ€è¿‘10æ¡
            with st.expander(f"â“ {item['question'][:100]}...", expanded=False):
                st.markdown(f"**ç­”æ¡ˆ:**")
                st.info(item['answer'])
                if item['sources']:
                    st.markdown(f"**æ¥æº:** {', '.join(item['sources'])}")
                st.caption(f"æ—¶é—´: {item['timestamp']}")
    
    with col2:
        st.header("ğŸ“ˆ ç»Ÿè®¡ä¿¡æ¯")
        
        # ç»Ÿè®¡å¡ç‰‡
        metric_col1, metric_col2 = st.columns(2)
        with metric_col1:
            st.metric("æ€»é—®ç­”æ•°", len(st.session_state.qa_history))
        with metric_col2:
            st.metric("æ–‡æ¡£å—æ•°", len(st.session_state.documents))
        
        # å¯¼å‡ºåŠŸèƒ½
        st.divider()
        st.header("ğŸ’¾ å¯¼å‡ºç»“æœ")
        
        if st.session_state.qa_history:
            # è½¬æ¢ä¸ºDataFrame
            df = pd.DataFrame(st.session_state.qa_history)
            
            # CSVä¸‹è½½
            csv = df.to_csv(index=False)
            st.download_button(
                label="ğŸ“¥ ä¸‹è½½CSV",
                data=csv,
                file_name=f"qa_results_{datetime.now().strftime('%Y%m%d_%H%M%S')}.csv",
                mime="text/csv",
                use_container_width=True
            )
            
            # JSONä¸‹è½½
            json_str = json.dumps(st.session_state.qa_history, ensure_ascii=False, indent=2)
            st.download_button(
                label="ğŸ“¥ ä¸‹è½½JSON",
                data=json_str,
                file_name=f"qa_results_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json",
                mime="application/json",
                use_container_width=True
            )

else:
    # æ¬¢è¿é¡µé¢
    st.info("ğŸ‘† è¯·å…ˆåœ¨ä¾§è¾¹æ ä¸Šä¼ PDFæ–‡æ¡£å¼€å§‹ä½¿ç”¨")
    
    # ä½¿ç”¨è¯´æ˜
    with st.expander("ğŸ“– ä½¿ç”¨è¯´æ˜", expanded=True):
        st.markdown("""
        ### å¿«é€Ÿå¼€å§‹
        1. **é…ç½®APIå¯†é’¥**: åœ¨ä¾§è¾¹æ è¾“å…¥OpenAI APIå¯†é’¥
        2. **ä¸Šä¼ æ–‡æ¡£**: é€‰æ‹©ä¿é™©äº§å“PDFæ–‡ä»¶
        3. **å¤„ç†æ–‡æ¡£**: ç‚¹å‡»"å¤„ç†æ–‡æ¡£"æŒ‰é’®
        4. **æé—®**: è¾“å…¥é—®é¢˜æˆ–é€‰æ‹©é¢„è®¾é—®é¢˜
        5. **å¯¼å‡ºç»“æœ**: ä¸‹è½½CSVæˆ–JSONæ ¼å¼çš„ç»“æœ
        
        ### åŠŸèƒ½ç‰¹ç‚¹
        - âœ… æ”¯æŒä¸­è‹±æ–‡PDFæ–‡æ¡£
        - âœ… è‡ªåŠ¨æå–è¡¨æ ¼æ•°æ®
        - âœ… 34ä¸ªé¢„è®¾ä¿é™©é—®é¢˜
        - âœ… æ‰¹é‡é—®ç­”åŠŸèƒ½
        - âœ… ç»“æœå¯¼å‡ºåŠŸèƒ½
        
        ### æ³¨æ„äº‹é¡¹
        - è¯·ç¡®ä¿PDFæ–‡ä»¶å°äº10MB
        - APIè°ƒç”¨ä¼šäº§ç”Ÿè´¹ç”¨
        - å»ºè®®ä½¿ç”¨é¢„è®¾é—®é¢˜ä»¥è·å¾—æœ€ä½³æ•ˆæœ
        """)

# é¡µè„š
st.divider()
st.caption("ğŸ”’ æ•°æ®å®‰å…¨ | ğŸ“§ æŠ€æœ¯æ”¯æŒ | v1.0.0")